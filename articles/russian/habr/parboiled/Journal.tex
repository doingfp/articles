\documentclass[12pt]{article}
\author{Pavel Popov}
\begin(document)

\section{Про Parboiled}\label{ux43fux440ux43e-parboiled}

\textbf{Часть 1. Почему Parboiled?}

Сегодня, в свете бурного роста популярности функциональных языков
программирования, всё чаще находят себе применение комбинаторы парсеров
--- инструменты, облегчающие разбор текста простым смертным. Такие
библиотеки, как \href{https://wiki.haskell.org/Parsec}{Parsec} (Haskell)
и \href{https://bitbucket.org/camlspotter/planck}{Planck} (OCaml) уже
успели хорошо себя зарекомендовать в своих экосистемах. Их удобство и
возможности в своё время подтолкнули создателя языка Scala, Мартина
Одерски, внести в стандартную библиотеку их аналог ---
\href{https://github.com/scala/scala-parser-combinators}{Scala Parser
Combinators} (ныне вынесены в
\href{http://mvnrepository.com/artifact/org.scala-lang.modules}{scala-modules}),
а знание и умение пользоваться подобными инструментами --- отнести к
обязательным требованиям к Scala-разработчикам
\href{http://www.scala-lang.org/old/node/8610}{уровня A3}.

Эта серия статей посвящена библиотеке
\href{https://github.com/sirthias/parboiled}{Parboiled} --- мощной
альтернативе и возможной замене для Scala Parser Combinators. В ней мы
подробно рассмотрим работу с текущей версией библиотеки --- Parboiled2,
а также уделим внимание Parboiled1, так как большая часть существующего
кода всё ещё использует именно её.

\textbf{Структура цикла:}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Часть 1. Почему Parboiled?
\item
  Часть 2. Сопоставление текста
\item
  Часть 3. Извлечение данных
\item
  Часть 4. Суровая действительность
\end{itemize}

\section{Введение}\label{ux432ux432ux435ux434ux435ux43dux438ux435}

Parboiled --- библиотека, позволяющая с легкостью разбирать (парсить)
языки разметки (такие как HTML, XML или JSON), языки программирования,
конфигурационные файлы, логи, текстовые протоколы и вообще что угодно
текстовое. Parboiled придётся весьма кстати, если вы захотите
разработать свой предметно-ориентированный язык
(\href{https://en.wikipedia.org/wiki/Domain-specific_language}{DSL}): с
её помощью вы сможете быстро получить
\href{https://ru.wikipedia.org/wiki/Абстрактное_синтаксическое_дерево}{абстрактное
синтаксическое дерево} и, вспомнив паттерн
\href{https://en.wikipedia.org/wiki/Interpreter_pattern}{интерпретатор},
исполнять команды вашего доменного языка.

На данный момент существует несколько версий данной библиотеки:

\begin{itemize}
\item
  Parboiled for Java --- самая первая версия библиотеки. Написана
  Маттиасом Доеницем (Matthias Doeniz) на Java и для Java. До сих пор
  пользуется популярностью, хоть и находится в состоянии «end of life».
  Если по воле случая она досталась вам в наследство, или же вы
  сознательно начинаете проект на Java, советую рассмотреть в качестве
  альтернативы \href{https://github.com/fge/grappa}{grappa} --- форк
  Parboiled1, который старательно поддерживается в работоспособном
  состоянии пользователем с ником \href{https://github.com/fge}{fge}.
\item
  Parboiled --- библиотека, теперь уже более известная как Parboiled1,
  появилась на свет после того, как Маттиас проникся скалой. Он сделал
  Scala-фронтэнд для Parboiled, заодно забросив поддержку Java-версии. С
  выходом Parboiled2 потихонечку перестает поддерживаться и Scala-версия
  Parboiled1, однако не смотря на это, списывать её со счетов пока что
  не стоит:

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    Parboiled2 пока что не научился всем фичам Parboiled1;
  \item
    Parboiled1 всё ещё используется гораздо шире, чем Parboiled2,
    поэтому если вас внезапно перебросят на какой-нибудь старый
    Scala-проект, высок шанс столкнуться именно с ним.
  \end{itemize}
\item
  Parboiled2 --- новейшая версия библиотеки, устраняющая ряд недостатков
  PB1. Работает быстрее и, что самое главное, поддерживается
  разработчиками.
\end{itemize}

Я писал эту статью с упором на Parboiled2 (кстати, дальше я буду писать
о нём в мужском роде, без слова «библиотека»), но иногда я буду
отвлекаться, чтобы рассказать о важных отличиях между первой и второй
версиями.

\subsection{Основные
возможности}\label{ux43eux441ux43dux43eux432ux43dux44bux435-ux432ux43eux437ux43cux43eux436ux43dux43eux441ux442ux438}

Краткая характеристика Parboiled2:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Следует принципам
  \href{https://en.wikipedia.org/wiki/Parsing_expression_grammar}{PEG}.
\item
  Генерирует однопроходные парсеры. Отдельный лексер не требуется.
\item
  Используется типобезопасный DSL, являющийся подмножеством языка Scala.
\item
  Оптимизации выполняются на этапе компиляции.
\end{itemize}

На практике это означает:

\begin{itemize}
\item
  Вам не нужно писать парсер голыми руками.
\item
  Читаемость, сравнимая с лучшими сортами BNF (по-моему, PB даже круче).
\item
  Можно использовать всю мощь PEG и свободно разбирать рекурсивные
  структуры данных, в то время как регулярные выражения не могут этого
  \href{https://en.wikipedia.org/wiki/Chomsky_hierarchy\#The_hierarchy}{по
  определению}. Да, регулярными выражениями вы не распарсите ни JSON, ни
  даже простейшее арифметическое выражение, что уж говорить о языках
  программирования. На StackOverflow есть
  \href{http://stackoverflow.com/a/1733489/1447225}{небезызвестная
  цитата в тему}:

  \begin{quote}
  Asking regexes to parse arbitrary HTML is like asking Paris Hilton to
  write an operating system.
  \end{quote}
\end{itemize}

\begin{itemize}
\item
  Даже если вам нужно разобрать линейную структуру, Parboiled2 (при
  использовании должных оптимизаций) будет работать быстрее регулярных
  выражений. Доказательства приведены в следующем разделе.
\item
  В отличие от генераторов парсеров, таких как
  \href{http://www.antlr.org/}{ANTLR}, вы освобождены от мороки с
  раздельной генерацией кода и последующей его компиляцией. Весь код с
  Parboiled пишется на Scala, поэтому вы получаете подсветку синтаксиса
  и проверку типов из коробки, так же как и отсутствие дополнительных
  операций над файлами грамматик, в то время как парсер, сгенерированный
  ANTLR, будет иметь две фазы синтаксического разбора. Правда, несмотря
  на это, ANTLR всё равно мощнее, документированее и стабильнее, и
  поэтому может оказаться предпочтительнее во многих (\emph{очень}
  нетривиальных) случаях.
\end{itemize}

\begin{itemize}
\item
  Скаловские парсер-комбинаторы работают медленно. Очень медленно.
  Неприлично медленно. Маттиас проводил сравнение производительности
  парсеров для Jackson и JSON, написанных с помощью Parboiled,
  Parboiled2 и Scala Parser Combinators. С неутешительными результатами
  для последних можно ознакомиться дальше по тексту.
\item
  В отличие от
  \href{http://martinfowler.com/bliki/LanguageWorkbench.html}{Language
  Workbenches}, Parboiled --- маленькая и простая в использовании
  библиотека. Вам не нужно скачивать плохо документированного
  тормозящего монстра и тратить драгоценные часы жизни на изматывающий
  поиск нужных менюшек и кнопочек всего-навсего для описания небольшого
  DSL. С другой стороны, вы не получите готовый текстовый редактор с
  подсветкой вашего DSL из коробки, вместо этого вам придется
  самостоятельно написать плагин для Vim, Emacs или вашей IDE, но это не
  делает Parboiled менее достойной альтернативой для разработки
  небольших предметно-ориентированных языков.
\end{itemize}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Parboiled успешно зарекомендовал себя во
  \href{https://github.com/sirthias/parboiled/wiki/Projects-using-parboiled}{многих
  проектах}, в том числе и в кровавом энтерпрайзе.
\end{itemize}

\subsection{Новое в версии
два}\label{ux43dux43eux432ux43eux435-ux432-ux432ux435ux440ux441ux438ux438-ux434ux432ux430}

Этот раздел, в основном, будет полезен и понятен тем, кто уже работал с
первой версией библиотеки. Новичкам, скорее всего, стоит вернуться к
этому списку после прочтения всего цикла статей.

Прежде всего, Parboiled2 успешно устраняет ряд детских болезней первой
версии:

\begin{itemize}
\item
  Появилась возможность использовать правила более вместительные, чем
  \texttt{Rule7}. Для этого была использована библиотека
  \href{https://github.com/milessabin/shapeless}{shapeless} с ее
  знаменитыми \texttt{HListами}: теперь одно правило может оперировать
  большим количеством значений на стеке. Это также означает, что в
  Parboiled2 появилась дополнительная зависимость, которой не было в PB1
  --- сама библиотека shapeless.
\item
  Добавлены недостающие конструкции. Так, в Parboiled1 нельзя было
  указать динамическое количество повторений для правила \texttt{nTimes}
  и приходилось использовать более «мягкое» правило \texttt{oneOrMore},
  что не давало нужной точности описания грамматики.
\item
  Добавлены встроенные примитивные терминалы. Появился новый класс
  \texttt{CharPredicate}, который содержит такие поля, как
  \texttt{AlphaNumeric}, \texttt{Hex}, \texttt{Printable},
  \texttt{Visible} и другие.
\item
  Добавлена возможность расширения и сужения предиката. Потребность
  исключить несколько символов из правила возникала и раньше, но только
  теперь это можно с легкостью взять и сделать, а не создавать белый
  список символов.
\end{itemize}

Кроме того:

\begin{itemize}
\item
  Parboiled2 использует макросы, что позволяет генерировать грамматику
  на этапе компиляции, а не во время выполнения, как это было в
  Parboiled1. Это многократно увеличивает производительность вашего
  парсера, так же как увеличивает количество проверок. В связи с этим
  блок \texttt{rule} стал обязательным, хотя Parboiled1 позволял в
  некоторых случаях обходиться без него. Это нововведение вы заметите в
  первую очередь, когда будете делать миграцию старого кода.
\item
  Улучшена система отчета об ошибках.
\item
  Появилась поддержка \href{http://www.scala-js.org/}{scala.js}.
  Демо-проект можно посмотреть
  \href{https://github.com/alexander-myltsev/parboiled2-scalajs-samples}{здесь}.
\end{itemize}

\section{Сравнения
производительности}\label{ux441ux440ux430ux432ux43dux435ux43dux438ux44f-ux43fux440ux43eux438ux437ux432ux43eux434ux438ux442ux435ux43bux44cux43dux43eux441ux442ux438}

Parboiled1 известен своей медлительностью (во всяком случае, по
отношению к парсерам, генерируемым ANTLR), вызванной тем, что все
действия по сопоставлению правил выполнялись в рантайме и компилятор не
мог производить над таким парсером каких-либо существенных оптимизаций.
В Parboiled2 во главу угла поставили производительность и многие вещи
были переделаны на макросах, благодаря чему компилятор получил свободу
действий при оптимизации, а пользователь --- долгожданную
производительность. Ниже мы продемонстрируем, каких неплохих результатов
добились разработчики.

\subsection{Parboiled против парсеров JSON, написанных прямыми
руками}\label{parboiled-ux43fux440ux43eux442ux438ux432-ux43fux430ux440ux441ux435ux440ux43eux432-json-ux43dux430ux43fux438ux441ux430ux43dux43dux44bux445-ux43fux440ux44fux43cux44bux43cux438-ux440ux443ux43aux430ux43cux438}

Parboiled --- это обобщённый инструмент для создания парсеров, а как
известно, специализированный инструмент всегда оказывается лучше
обобщённого в решении своей специализированной задачи. В мире Java
существует небольшое количество парсеров JSON, написанных вручную
древними эльфийскими мастерами, и Александр Мыльцев (один из
разработчиков Parboiled2) проверил, насколько сильно Parboiled
проигрывает в производительности этим артефактам.
\href{http://myltsev.name/ScalaDays2014/\#/}{Результаты} оказались
достаточно оптимистичными, особенно в случае с Parboiled2.

\begin{verbatim}
  Тест-кейс                           │ Время, мс │
──────────────────────────────────────┼───────────┼─────────────────────────────────
  Parboiled1JsonParser                │     85.64 │ ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
  Parboiled2JsonParser                │     13.17 │ ▇▇▇▇
  Json4SNative                        │      8.06 │ ██▍
  Argonaut                            │      7.01 │ ▇▇
  Json4SJackson                       │      4.09 │ ▇
\end{verbatim}

\subsection{Parboiled против регулярных
выражений}\label{parboiled-ux43fux440ux43eux442ux438ux432-ux440ux435ux433ux443ux43bux44fux440ux43dux44bux445-ux432ux44bux440ux430ux436ux435ux43dux438ux439}

Благодаря использованию статических оптимизаций, Parboiled2 способен
работать значительно быстрее регулярных выражений (как минимум тех, что
идут в комплекте с библиотекой классов Java). Вот немного подтверждающих
данных из
\href{https://groups.google.com/forum/\#!msg/parboiled-user/XATcJRLTXjA/XSmf3n6gZSwJ}{списка
рассылки}:

\begin{verbatim}
  Тест-кейс                           │ Время, мс │
──────────────────────────────────────┼───────────┼───────────────────────────────────
  Parboiled2 (warmup)                 │   1621.21 │ ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
  Parboiled2                          │    409.16 │ ▇▇▇▇▇▇▇▇
  Parboiled2 w/ better types (warmup) │    488.92 │ ▇▇▇▇▇▇▇▇▇▇
  Parboiled2 w/ better types          │    134.68 │ ▇▇▇
  Regex (warmup)                      │    621.95 │ ▇▇▇▇▇▇▇▇▇▇▇▇
  Regex                               │    620.38 │ ▇▇▇▇▇▇▇▇▇▇▇▇
\end{verbatim}

\subsection{Parboiled против Scala Parser
Combinators}\label{parboiled-ux43fux440ux43eux442ux438ux432-scala-parser-combinators}

В списке рассылки можно найти и
\href{https://groups.google.com/forum/\#!topic/parboiled-user/bGtdGvllGgU}{другой
тест производительности}, который неплохо согласуется с первым (про
JSON) и содержит данные для сравнения со Scala Parser Combinators. Всё
очень и очень печально.

\begin{verbatim}
  Тест-кейс                           │ Время, мс │
──────────────────────────────────────┼───────────┼─────────────────────────────────
  Parboiled1JsonParser                |     73.81 | ▇
  Parboiled2JsonParser                |     10.49 | ▎
  ParserCombinators                   |   2385.78 | ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
\end{verbatim}

\section{Чего Parboiled не
может}\label{ux447ux435ux433ux43e-parboiled-ux43dux435-ux43cux43eux436ux435ux442}

Большинство статей про комбинаторы парсеров начинается с изматывающих
объяснений того, что такое PEG, с чем его есть и почему его надо
бояться. Для того чтобы парсить конфиги, досконально разбираться в этом
не обязательно, но знать об ограничениях данного типа грамматик всё
равно стоит. Итак, Parboiled принципиально не умеет:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Разбирать леворекурсивные грамматики. Это не под силу всем нисходящим
  парсерам (top-down parsers), к коим относятся и PEG. Однако,
  леворекурсивную грамматику можно
  \href{http://neerc.ifmo.ru/wiki/index.php?title=Устранение_левой_рекурсии}{адаптировать}.
\end{itemize}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Разбирать грамматики на отступах (indentation-based grammars),
  например Python или YAML. Не получается это сделать из-за того, что
  сгенерированный парсер является однопроходным, без отдельного лексера.
  Разбор отступов же выполняется на этапе лексического анализа. У этой
  проблемы есть простое решение: напишите препроцессор, который
  расставит виртуальные маркеры до (\texttt{INDENT}) и после
  (\texttt{DEDENT}) выхода в отступ. В Parboiled1 имеются для этого
  \href{https://github.com/sirthias/parboiled/wiki/Indentation-Based-Grammars}{стандарные
  инструменты}, но для Parboiled2 подобную процедуру пока что придётся
  выполнять самостоятельно.
\end{itemize}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Использовать потоковый ввод (streaming input). PEG используют поиск с
  возвратом, он же
  \href{https://en.wikipedia.org/wiki/Backtracking}{бэктрекинг}.
  Теоретически, этот недостаток можно устранить при помощи буферизации
  потока, но ничто не мешает написать такую грамматику, в которой
  происходит возврат к самому началу. Поэтому, чтобы эта идея заработала
  на практике, необходимо научиться определять по грамматике границы
  чанков, между которыми возврат невозможен. Матиас весьма
  \href{https://groups.google.com/d/msg/parboiled-user/b7PH49fiFco/gGt46xe3Ae4J}{заинтересован}
  в разработке этой фичи, так что возможно ее появление в следующих
  релизах.
\end{itemize}

В следующей части я расскажу о том, как в Parboiled описывается
пользовательская грамматика, а ещё мы напишем простой распознаватель для
древовидного формата конфигурационных файлов.

\section{Подготовительные
работы}\label{ux43fux43eux434ux433ux43eux442ux43eux432ux438ux442ux435ux43bux44cux43dux44bux435-ux440ux430ux431ux43eux442ux44b}

Перед началом работы с библиотекой добавим её в classpath. В Maven,
например, это делается так:

\begin{verbatim}
<dependency>
    <groupId>org.parboiled</groupId>
    <artifactId>parboiled_2.11</artifactId>
    <version>2.1.0</version>
</dependency>
\end{verbatim}

Я использую Scala 2.11, однако существуют артефакты и для 2.10.

\section{Язык описания правил (Rule
DSL)}\label{ux44fux437ux44bux43a-ux43eux43fux438ux441ux430ux43dux438ux44f-ux43fux440ux430ux432ux438ux43b-rule-dsl}

Вся функциональность Parboiled реализуется поверх синтаксиса языка Scala
при помощи специализированного DSL. Поэтому описание парсера на самом
деле есть ни что иное, как объявление класса, производного от
\texttt{org.parboiled.Parser}. В качестве примера напишем парсер,
который ничего не делает, что не мешает ему существовать и радоваться
жизни:

\begin{verbatim}
import org.parboiled2._

class MyParser(val input: ParserInput) extends Parser {
  // Здесь описана ваша грамматика
}
\end{verbatim}

Конструкции DSL и ряд полезных классов добавляются в зону видимости
всего одной директивой импорта. Хочу отметить, что наличие параметра
\texttt{input} в конструкторе является обязательным: это означает, что
для каждого нового набора входных данных нужно создавать новый
объект-парсер. Вначале меня это очень сильно пугало, но я перестал
бояться, когда увидел, как быстро оно работает.

\subsection{Правила для отдельных
символов}\label{ux43fux440ux430ux432ux438ux43bux430-ux434ux43bux44f-ux43eux442ux434ux435ux43bux44cux43dux44bux445-ux441ux438ux43cux432ux43eux43bux43eux432}

Итак, когда никчёмный парсер у нас уже имеется, нужно добавить в него
несколько правил, в соответствии с которыми он и будет обрабатывать
данные. Если вы работали с Parboiled1, этот раздел можно просто
пролистать, так как мои объяснения могут показаться вам излишне
подробными.

Начнем с терминалов. Этот термин будет использоваться в дальнейшем,
поэтому попробуем дать ему здесь определение (не совсем, впрочем,
строгое):

\begin{quote}
Терминал --- это простейшее атомарное правило, не требующие
дополнительных определений
\end{quote}

Давайте опишем два простейших правила: первое должно распознать
некоторый наперёд известный символ, второе --- строку:

\begin{verbatim}
def MyCharRule   = rule { ch('a') }
def MyStringRule = rule { str("string") }
\end{verbatim}

Каждый раз обозначать свои намерения подобным образом весьма
утомительно. И здесь нам на помощь приходит механизм неявных
преобразований (implicit conversions), который позволяет сделать правила
короче:

\begin{verbatim}
def MyCharRule   = rule { 'a' }
def MyStringRule = rule { "string" }
\end{verbatim}

Строки сопоставляются с точным учётом регистра символов. Тем не менее,
существует множество языков, не чувствительных к регистру (например
SQL). Для них существует правило \texttt{ignoreCase}, сопоставляющее
входную строку независимо от ее регистра. Передаваемая в него строка
обязательно должна быть в нижем регистре:

\begin{verbatim}
def StringWithCaseIgnored = rule { ignoreCase("string") }
\end{verbatim}

Подробнее о правилах (или «продукциях», если вам так нравится больше)
будет рассказано в следующей статье. Все приведенные выше (и ниже)
правила имеют тип \texttt{Rule0}. Правила бывают разных типов, но сейчас
нам необходимо знать лишь то, что \texttt{Rule0} обозначает, что правило
сопоставляет с собой входную строку и говорит, совпало или нет. Мы не
указали тип потому, что механизм вывода типов языка пока легко
справляется и сам. Однако, ничто не мешает нам указать тип явно:

\begin{verbatim}
def StringWithCaseIgnored: Rule0 = rule { ignoreCase("string") }
\end{verbatim}

В Parboiled существуют особенные терминалы (они же синтаксические
предикаты):

\begin{itemize}
\item
  \texttt{ANY} --- любой символ, кроме \texttt{EOI}.
\item
  \texttt{EOI} (End of Input) --- виртуальный символ-маркер конца ввода,
  который вы обязательно захотите добавить в главное правило своего
  парсера. Определяется \texttt{EOI} так:

\begin{verbatim}
val EOI = '\uFFFF'
\end{verbatim}
\end{itemize}

Несмотря на то, что символ U+FFFF зарезервирован для внутреннего
использования стандартом Юникода, на практике он может запросто
встретиться в пользовательском вводе и изменить поведение парсера.
Поэтому будьте внимательны с текстом, который попадает на вход.

Кроме того, если вы не добавите \texttt{EOI} в конце главного правила и
при сопоставлении возникнет ошибка, то о ней вы не узнаете, так как
парсер будет считать, что входные данные ещё не закончились и будет
ожидать поступления новых данных. Поэтому, что бы вы не подали на вход,
на выходе вас ожидает бессмысленный Success.

Из правил \texttt{chr} и \texttt{str} вряд ли можно составить полезный
парсер, поэтому первым шагом к осмысленности станет возможность
определять \emph{диапазон} допустимых симовлов. В Parboiled2 это
делается очень легко:

\begin{verbatim}
def Digit      = rule { '0' - '9' }
def AlphaLower = rule { 'a' - 'z' }
\end{verbatim}

Оба эти правила сопоставят за раз максимум один символ из диапазона (или
не сопоставят ни одного). Хотя написать конкретно эти два правила в PB2
очень просто, делать это нет необходимости: они уже определены в объекте
\texttt{CharPredicate}. Parboiled1, напротив, заставлял вручную
создавать эти правила, практически каждый раз, когда вы пишете очередной
парсер. Поэтому я носил свою библиотечку примитивов из проекта в проект
(уверен, что не я один так делал). Теперь моя библиотечка заметно
подыстощилась благодаря появлению \texttt{CharPredicate}. В него входят,
например, следующие правила (думаю, что из названий будет понятно, каким
категориям символов они соответствуют):

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{CharPredicate.All} (работает почти так же, как \texttt{ANY},
  но показывает худшую производительность на больших диапазонах
  символов);
\item
  \texttt{CharPredicate.Digit};
\item
  \texttt{CharPredicate.Digit19};
\item
  \texttt{CharPredicate.HexDigit} и много других правил.
\end{itemize}

Если вас не устаивают имеющиеся правила, вы всегда сможете определить
свой собственный символьный предикат, для этого необходимо использовать
метод \texttt{from}:

\begin{verbatim}
CharPredicate from (_.isSpaceChar)
\end{verbatim}

Кроме того, для символьных предикатов определены операторы
\texttt{except} (\texttt{-\/-}) и \texttt{union} (\texttt{++}), которых
не было в PB1. Лично я от этого отсутствия очень страдал: приходилось
замыкать правило «с другой стороны», перечисляя полностью черный или
белый список символов в зависимости от ситуации. Правило \texttt{-\/-}
можно так же назвать разностью, так как роль у него накая же, что и у
\href{https://ru.wikipedia.org/wiki/Разность_множеств}{разности двух
множеств}.

\begin{verbatim}
// Сопоставит любой печатный символ, если это не кавычка.
def AllButQuotes = rule { CharPredicate.Visible -- "\"" -- "'" }

// Неплохо подойдет для определения идентификатора. Обратите внимание, как
// AlphaNum объединяется с нижним подчеркиванием.
def ValidIdentifier = rule {
  CharPredicate.Alpha ~ zeroOrMore(CharPredicate.AlphaNum ++ "_") }
\end{verbatim}

Полезно будет знать ещё о двух правилах: \texttt{anyOf} и
\texttt{noneOf}. Они очень похожи на \texttt{except} и \texttt{union},
но работают на всём пространстве символов \texttt{ANY}. И самое главное:
в этом пространстве они работают быстрее. Эти функции могут принимать на
вход строку, состоящую из перечислений символов. Например:

\begin{verbatim}
// Определит, является ли символ одной из арифметических операций.
def ArithmeticOperation = rule { anyOf("+-*/^") }

// Сопоставит всё, кроме перечисленных пробельных символов и EOI.
def WhiteSpaceChar = rule { noneOf(" \t\n") }
\end{verbatim}

Иногда возникает вопрос, что же выбрать: \texttt{anyOf}/\texttt{noneOf}
или \texttt{CharPredicate}? Заранее предопределенный символьный предикат
будет работать быстрее для 7-битных символов ASCII. «Заранее
предопределенный» написано не просто так, и в разделе «Best Practices»
части 4 будет рассказано, почему. Однако для очень больших символьных
диапазонов \texttt{CharPredicate} ведёт себя откровенно плохо, и тогда
на помощь должны прийти \texttt{anyOf} и \texttt{noneOf}.

\subsection{Цепочки
правил}\label{ux446ux435ux43fux43eux447ux43aux438-ux43fux440ux430ux432ux438ux43b}

\subsubsection{N.times}\label{n.times}

Сопоставлять единичные символы не интересно, поэтому перейдем к более
сложным правилам. Начнём с \texttt{times}, которое позволяет сопоставить
одно правило несколько раз подряд. Количество повторений должно быть
точным и заранее известным.

\begin{verbatim}
def BartLearningParboiled = rule {
  100 times "I will never write a parser again. "
}
\end{verbatim}

Некоторые грамматики требуют жесткого диапазона числа повторений,
например
\href{http://www.chukfamily.ru/Kornei/Prosa/Ot2do5/Ot2do5.htm}{от двух
до пяти}. В новом Parboiled это можно легко устроить:

\begin{verbatim}
def FutureOfCxx = rule { 'C' ~ (2 to 5).times('+') }
\end{verbatim}

А в старом --- существует правило \texttt{nTimes}, которое, требует
указания точного числа повторений. В случае, если точное количество
повторений заранее не известно, вам помогут следующая пара правил.

\subsubsection{zeroOrMore}\label{zeroormore}

Как вы уже наверное догадались из названия, zeroOrMore сопоставляет
последновательность из нуля и более вхождений указанного правила.
Внимательный читатель уже заметил это правило в примерах и оно ему,
скорее всего, показалось хорошо знакомым: в регулярных выражениях точно
такая же операция обозначается звёздочкой, а любители академической
терминологии, кроме того, знают, что она называется
\href{https://ru.wikipedia.org/wiki/\%D0\%97\%D0\%B2\%D0\%B5\%D0\%B7\%D0\%B4\%D0\%B0_\%D0\%9A\%D0\%BB\%D0\%B8\%D0\%BD\%D0\%B8}{звездой
Клини}. В любом случае, использовать это правило очень просто:

\begin{verbatim}
def Whitespace = rule { anyOf(" \n\t") }
def OptWs      = rule { zeroOrMore(Whitespace) }
\end{verbatim}

\subsubsection{oneOrMore}\label{oneormore}

Правило, похожее на предыдущее. Оно делает почти то же самое, что и
\texttt{zeroOrMore}, но требует, чтобы по крайней мере одно повторение
присутствовало во входных данных. Идентично плюсу Клини для регулярных
грамматик.

\begin{verbatim}
def UnsignedInteger = rule { oneOrMore(CharPredicate.Digit) }
\end{verbatim}

\subsubsection{Разделитель цепочек:
separatedBy}\label{ux440ux430ux437ux434ux435ux43bux438ux442ux435ux43bux44c-ux446ux435ux43fux43eux447ux435ux43a-separatedby}

Часто приходится иметь дело со случаем, когда множество элементов
записывается подряд через некоторый разделитель: это и CSV, и
определения списков или массивов, и перечисления аргументов функции
через запятую, и многое другое. В Parboiled2 парсинг таких
последовательностей делается легко и непринужденно:

\begin{verbatim}
def CommaSeparatedNumbers = rule { oneOrMore(UnsignedInteger).separatedBy(",") }
\end{verbatim}

Однако, первая версия использует для этого менее элегантный синтаксис:

\begin{verbatim}
def CommaSeparatedNumbers = rule { oneOrMore(UnsignedInteger, separator = ",") }
\end{verbatim}

\subsubsection{Оператор последовательности
(\textasciitilde{})}\label{ux43eux43fux435ux440ux430ux442ux43eux440-ux43fux43eux441ux43bux435ux434ux43eux432ux430ux442ux435ux43bux44cux43dux43eux441ux442ux438}

Для того чтобы указать последовательность правил используется оператор
\texttt{\textasciitilde{}}. В регулярных выражениях нет необходимости в
подобном операторе, там этот факт записывается непосредственным образом,
так же, как и в некоторых вариантах BNF. Для примера напишем (предельно
упрощенное) правило которое сопоставляет дату определенного формата:

\begin{verbatim}
import CharPredicate.Digit

// Дата должна иметь следующий формат: "yyyy-mm-dd"
def SimplifiedRuleForDate = rule { Year ~ "-" ~ Month ~ "-" ~ Day }

def Year  = rule { Digit ~ Digit ~ Digit ~ Digit }
def Month = rule { Digit ~ Digit }
def Day   = rule { Digit ~ Digit }
\end{verbatim}

Как видите, правило максимально упрощено, и я прекрасно отдаю отчет
тому, что у нас может быть 99 дней и 99 месяцев. Не все проверки имеет
смысл оставлять на уровне парсера: мы всё равно передадим сопоставленную
строку на вход какому-нибудь классу для работы с датой и временем,
который догадается выполнить валидацию, и вернет результат, обернутый в
Option. А вот грамматику этим мы заметно упростим. Попытка заставить
парсер выполнить все возможные и невозможные проверки часто приводит к
\href{http://www.ex-parrot.com/~pdw/Mail-RFC822-Address.html}{подобным
результатам}.

\subsubsection{«Необязательное» правило
(optional)}\label{ux43dux435ux43eux431ux44fux437ux430ux442ux435ux43bux44cux43dux43eux435-ux43fux440ux430ux432ux438ux43bux43e-optional}

Если бы существовало правило \texttt{zeroOrOne}, то это и был бы
\texttt{optional}: либо есть одно вхождение, либо вхождений нет совсем.
Давайте разберем следующий пример: в разных семейства операционных
систем маркер конца строки кодируется по-разному. Например, в
Unix-подобных операционных системах нужен только символ
\texttt{\textbackslash{}n}, тогда как в Windows исторически используется
последовательность из двух символов: \texttt{\textbackslash{}r} и
\texttt{\textbackslash{}n}. И если мы хотим обрабатывать текст,
созданный в любой из этих систем, то можно использовать следующее
правило для конца строки:

\begin{verbatim}
def Newline = rule { optional('\r') ~ '\n' }
\end{verbatim}

\subsubsection{Упорядоченный выбор
(\textbar{})}\label{ux443ux43fux43eux440ux44fux434ux43eux447ux435ux43dux43dux44bux439-ux432ux44bux431ux43eux440}

Аналог оператора \texttt{\textbar{}} в регулярных выражениях, неспроста
называемый \emph{упорядоченным} выбором (ordered choice). Предположим,
что нам нужно распознать число, у которого может быть знак, а может, и
не может. Знак, если он есть, может быть двух типов: положительный и
отрицательный, разберемся сначала с ним:

\begin{verbatim}
def Signum = rule { '+' | '-' }
\end{verbatim}

Знак может вовсе отсутствовать в записи положительного числа:

\begin{verbatim}
def MaybeSign = rule { optional(Signum) }
\end{verbatim}

Тогда само число в любом случае представится в виде последовательности
из возможного вхождения знака числа и его модуля --- числа без знака:

\begin{verbatim}
def Integer = rule { MaybeSign ~ UnsignedInteger }
\end{verbatim}

Порядок перечисления вариантов в правиле \texttt{Signum} имеет значение:
выбирается самый первый из подошедших вариантов, что исключает
возможность появления неоднозначности у грамматики. И да, так работают
все без исключения PEG-парсеры. Так что, если вам нужно разобрать
выражение на языке C, начинать перечисление нужно с самых длинных
операций, чтобы они сопоставились первыми, как и предписывает стандарт.
Упрощённо правило может выглядеть, например, так:

\begin{verbatim}
def Operator = rule {
  "+=" | "-=" | "*=" | "/=" | "%=" | "&=" | "^=" | "|=" | "<<=" | ">>=" |
  "<<" | ">>" | "<=" | ">=" | "==" | "!=" |
  "||" | "&&" | "->" | "++" | "--" |
  "<"  | ">"  | "+"  | "-"  | "&"  | "|" | "." |
  "*"  | "/"  | "!"  | "~"  | "^"  | "=" | ","
}
\end{verbatim}

Порядок перечисления может быть самым различным, но нужно обеспечить,
чтобы в нём \texttt{+} всегда шёл после \texttt{+=} и \texttt{++}, а
\texttt{\textless{}} --- после \texttt{\textless{}=} и
\texttt{\textless{}\textless{}} (а \texttt{\textless{}\textless{}}, в
свою очередь, после \texttt{\textless{}\textless{}=}). В противном
случае может случиться, что составной оператор присваивания
\texttt{\textless{}\textless{}=} распарсится в последовательность
{[}\texttt{\textless{}=}, \texttt{=}{]}, а то и вовсе
{[}\texttt{\textless{}}, \texttt{\textless{}}, \texttt{=}{]}.

Если правило выбора становится избыточно сложным и нам не хочется
полагаться на порядок его элементов, стоит сгруппировать их по общим
префиксам (факторизовать парсер):

\begin{verbatim}
def Operators = rule {
  ("+" ~ optional("=" | "+")) |
  ("<" ~ optional("=" | ("<" ~ optional("=")))) | ...
}
\end{verbatim}

Заметим, однако, что ни один из наших примеров не сможет автоматически
учитывать приоритеты операторов, для этого придётся прибегнуть к более
изощрёным правилам.

\subsubsection{Немного
сахара}\label{ux43dux435ux43cux43dux43eux433ux43e-ux441ux430ux445ux430ux440ux430}

Для \texttt{optional}, \texttt{oneOrMore} и \texttt{zeroOrMore}
существует синтаксический сахар, позволяющий сделать определения ещё
короче: \texttt{.?}, \texttt{.+} и \texttt{.*}. Пожалуйста, используйте
их мудро: при злоупотреблении ими, ваши правила будут читаться немногим
лучше, чем регулярки. С помощью этих «ярлыков» мы можем сделать описание
наших правил менее многословным:

\begin{verbatim}
import CharPredicate.Digit
def SignedInteger   = rule { (+ | -).? ~ Digit.+ }

def Newline = rule { '\r'.? ~ '\n' }

def OptWs = rule { WhitespaceChar.* }
\end{verbatim}

\subsubsection{Запуск
парсера}\label{ux437ux430ux43fux443ux441ux43a-ux43fux430ux440ux441ux435ux440ux430}

Для того, чтобы заставить написанный парсер сделать хоть что-то
полезное, нужно вызвать метод \texttt{run} его главного (корневого)
правила. Если вы пишете модульный-тест для парсера, то возможно, имеет
смысл вызывать этот метод и для других правил. Скобочки после метода при
этом обязательны.

Давайте заставим работать наш бесполезный парсер, умеющий сопоставлять
только одну строковую константу. Итак наш парсер определён следующим
образом (не забываем про \texttt{EOI}):

\begin{verbatim}
import org.parboiled2._

class MyParser(val input: ParserInput) extends Parser {
  def MyStringRule: Rule0 = rule { ignoreCase("match") ~ EOI }
}
\end{verbatim}

Теперь где-нибудь в другом месте создадим несколько экземпляров парсеров
и подадим им на вход разные данные:

\begin{verbatim}
val p1 = new MyParser("match")
val p2 = new MyParser("Match")
val p3 = new MyParser("much")

// по-умолчанию возвращают scala.util.Try
p1.MyStringRule.run()      // Success
p2.MyStringRule.run()      // Success
p3.MyStringRule.run()      // Failure
\end{verbatim}

Прогон правил в Parboiled2 намного проще, чем в Parboiled1, для которого
существует целый зоопарк раннеров (parser runners), которые приходится
дополнительно вызывать. За более подробной информацией прошу в раздел
«Отчеты об ошибках» части 4.

\subsubsection{Вложенные структуры
данных}\label{ux432ux43bux43eux436ux435ux43dux43dux44bux435-ux441ux442ux440ux443ux43aux442ux443ux440ux44b-ux434ux430ux43dux43dux44bux445}

Разбор рекурсивных структур --- это то, что может Parboiled и не могут
регулярные выражения. В Parboiled это получается естественно и
непринужденно, что мы и продемонстрируем на последующих примерах.
Единственное дополнительное усилие, которое от вас требуется --- явно
объявить тип правил, участвующих в рекурсии.

Разбор рекурсивных структур обычно иллюстрируют на примере калькулятора
арифметических выражений. По моему мнению, пример совершенно не
нагляден. Поэтому мы рассмотрим вымышленный формат конфигурационных
файлов, состоящий из именованных блоков, которые содержат пары
«ключ---значение».

\section{Формат BKV
(Block-Key-Value)}\label{ux444ux43eux440ux43cux430ux442-bkv-block-key-value}

В качестве примера будет использоваться формат «BKV», который был
придуман специально для этого туториала. Он вдохновлялся форматом
\href{https://github.com/typesafehub/config/blob/master/HOCON.md}{HOCON}
и, собственно, является его подмножеством. BKV состоит из пар
ключ---значение и блоков, внутри которых могут размещаться пары.
Выглядит это примерно так:

\begin{verbatim}
server.name = "webserver"
server {
  port    = "8080"
  address = "192.168.88.88"

  settings {
    greeting_message = "Hello!\n It's me!"
  }
}
\end{verbatim}

Как видите, формат прост и незатейлив, хотя строки с экранированием
(escaping) могут напугать тех, кто никогда не писал парсеры.
Экранирование очень часто встречается при синтаксическом разборе,
поэтому мы обязательно и в подробностях его рассмотрим.

\subsection{Экранированные
строки}\label{ux44dux43aux440ux430ux43dux438ux440ux43eux432ux430ux43dux43dux44bux435-ux441ux442ux440ux43eux43aux438}

Для того, чтобы при синтаксическом разборе не иметь проблем с
пробельными и непечатными символами в большинстве грамматик строки
заключаются в двойные или одинарные кавычки (или их некое подобие,
например, могут использоваться открывающие и закрывающие угловые
скобки). Непечатные символы и кавычки --- экранируются.

Для того, чтобы написать распознаватель экранированных строк, необходимо
определиться со следующими элементами синтаксиса:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Символы, открывающие и закрывающиие строку (в нашем случае это один и
  тот же символ --- двойная кавычка).
\item
  Символ экранирования (в нашем случае это символ обратного слеша).
\item
  Набор символов-мнемоник для обозначения непечатных символов (мы будем
  поддерживать, как минимум,
  \texttt{\textquotesingle{}\textbackslash{}n\textquotesingle{}},
  \texttt{\textquotesingle{}\textbackslash{}t\textquotesingle{}} и
  \texttt{\textquotesingle{}\textbackslash{}v\textquotesingle{}}).
\end{itemize}

Сначала попробуем описать правило для квотированной строки без
экранирования:

\begin{verbatim}
def OverlySimplifiedQuotedString = rule {
  '"' ~ zeroOrMore(AllowedChar) ~ '"'
}
\end{verbatim}

Поскольку пустые строки тоже возможны, между кавычками мы используем
правило \texttt{zeroOrMore}. Очевидно, что двойная кавычка в перечень
допустимых символов не входит. Что же тогда разрешено? Всё, что не
запрщено. Поэтому для нашего случая список разрешенных символов выглядит
так:

\begin{verbatim}
def AllowedChar = rule { noneOf("\"") }
\end{verbatim}

Без двойной кавычки жить можно, но сложно. Но что будет, если мы добавим
кавычку внутрь строки? Встретив её, парсер подумает, что строка
закончилась, и взорвётся сообщением об ошибке на следующем же символе.

Символ экранирования предупреждает парсер о том, что следущий символ
особенный. Алгоритм выглядит таким образом: парсер ожидает один из
разрешенных символов или экранированную последовательность, а
экранированная последовательность состоит из символа экранирования и
следующего за ним оператора выбора одного из символов:

\begin{verbatim}
def AllowedChar = rule {
  noneOf("\"\\") | EscapeSequence
}

// Поддерживаются последовательности: \", \\, \n, \a, \f, \v.
def EscapeSequence = rule {
  '\' ~ anyOf("\"\\nafv")
}
\end{verbatim}

Разобравшись, как это работает, можно переходить к написанию финального
варианта правил для экранирования. Для этого предлагаю создать
выделенный трейт:

\begin{verbatim}
import org.parboiled2._

object QuotedStringSupport {
  val CharsToBeEscaped = "abfnrtv\\\""
  val Backslash = '\\'
  val AllowedChars = CharPredicate.Printable -- Backslash -- '"'
}

trait QuotedStringSupport { this: Parser =>
  import QuotedStringSupport._

  def QuotedString: Rule0 = rule {
    '"' ~ QuotedStringContent  ~ '"'
  }

  def QuotedStringContent: Rule0 = rule {
    oneOrMore(AllowedChars | DoubleQuotedStringEscapeSequence)
  }

  def DoubleQuotedStringEscapeSequence = rule {
    '\\' ~ anyOf(CharsToBeEscaped)
  }
}
\end{verbatim}

Теперь, когда мы расквитались со строками и выделили соответствующую
функциональность в отдельный трейт, перейдем к самому формату.

\subsection{Вспомогательные
терминалы}\label{ux432ux441ux43fux43eux43cux43eux433ux430ux442ux435ux43bux44cux43dux44bux435-ux442ux435ux440ux43cux438ux43dux430ux43bux44b}

В написании парсеров существует два подхода: «от общего к частному» и
«от частного к общему». Обычно грамматики описываются согласно первому,
но это всего-лишь туториал, поэтому начнем с деталей помельче, а затем
обобщим.

Начем описание со вспомогательных элементов, а именно, с пробелов. В
нашем случае пробелами будут являться символы: `', `\n' и `\t'. Конечно
же, пробельных символов в природе существует куда больше, но в примере
мы ограничимся тремя. Разобраться с пробелами можно разными способами:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  перечислить символы через оператор упорядоченного выбора;
\item
  объявить свой \texttt{CharPredicate}, содержащий эти три символа;
\item
  использовать \texttt{anyOf}.
\end{itemize}

Мы воспользуемся последним. При этом учтём, что в некоторых местах
пробелов может быть несколько, в других --- не быть вовсе, а кое-где
пробелы должны быть обязательно (но нашему формату обязательные пробелы
не требуются):

\begin{verbatim}
val WhitespaceChars = "\n\t "
def WhiteSpace = rule { anyOf(WhitespaceChars) }
def OptWs      = rule { zeroOrMore(WhiteSpace) }
\end{verbatim}

Правило, описывающее перевод строки мы объявляли ранее:

\begin{verbatim}
def Newline = rule { optional('\r') ~ '\n' }
\end{verbatim}

Ключ и имя блока представляют собой идентификатор, похожий на тот, что
вы можете встретить в различных языках программирования. Идентификатор
должен начинаться либо с буквы английского алфавита (регистр не имеет
значения), либо с символа нижнего подчеркивания. В середине может
содержать цифры а так же буквы английского алфавита (строчные и
заглавные). Вхождение точки, в середине идентификатора тоже допустимо.
Перед тем как объявлять ключ, объявим правило, описывающее
идентификатор. (Аналогичные правила будут применяться для имени блока).
Нам необходимо два символных предиката: для первого и последующих
символов.

\begin{verbatim}
// Первый символ идентификатора
val IdentifierFirstChar = CharPredicate.Alpha ++ '_'

// Для последующих символов
val IdentifierChar      = CharPredicate.AlphaNum ++ '.' ++ '_'
\end{verbatim}

Объявим также символы начала и конца блока:

\begin{verbatim}
val BlockBeginning  = '{'
val BlockEnding     = '}'
\end{verbatim}

Теперь, когда у нас имеются все необходимые вспомогательные терминалы,
займёмся блоками покрупнее.

\subsection{Пары
ключ---значение}\label{ux43fux430ux440ux44b-ux43aux43bux44eux447ux437ux43dux430ux447ux435ux43dux438ux435}

Теперь перейдём к синтаксису пар «ключ--значение». Потребуем, чтобы ключ
представлял собой валидный идентификатор, как описанно выше, а значение
было квотированной строкой, как тоже описано выше. Итак, начнем с
определения идентификатора:

\begin{verbatim}
def Identifier = rule {
  IdentifierFirstChar ~ zeroOrMore(IdentifierChar)
}
\end{verbatim}

Возможно, нам не стоило задавать идентификатор достаточно жестким
правилом, однако в большинстве грамматик с которыми вам, скорее всего
придется столкнуться,используются аналогичные правила. Например,
идентификаторам запрещено начинаться с цифры, ввиду наличия
целочисленных литералов, различные символы могут являться валидными
операторами. Правило описывающее ключ, будет выглядеть так:

\begin{verbatim}
def Key = rule { Identifier }
\end{verbatim}

Для описания значения воспользуемся уже имеющимся правилом (для этого
нам всего-то нужно подмешать написанный нами ранее трейт):

\begin{verbatim}
def Value = rule { DoubleQuotedString }
\end{verbatim}

Теперь опишем правило для всей пары целиком. Тут стоит еще раз напомнить
о том, что Parboiled является PEG, из этого следует, что нам постоянно
нужно помнить о пробелах и сообщать правилу о местах, где они могут
встречаться.

\begin{verbatim}
def KeyValuePair = rule { Key ~ OptWs ~ "=" ~ OptWs ~ Value }
\end{verbatim}

\subsection{Вложенные
блоки}\label{ux432ux43bux43eux436ux435ux43dux43dux44bux435-ux431ux43bux43eux43aux438}

Блок ограничен фигурными скобками и может содержать внутри как пары
«ключ---значение», так и другие блоки. Поэтому для начала нужно стереть
различия между блоками и парами ключ---значение, обозвав и те, и другие
узлами (nodes) синтаксического дерева. Это делается следующим кодом:

\begin{verbatim}
// Тип правила обязателен к указанию, иначе не взлетит!
def Node: Rule0 = rule { KeyValuePair | Block }
\end{verbatim}

Так как и блок, и корневая структура состоят из списка узлов, нам нужно
объявить правило для этого списка:

\begin{verbatim}
def Nodes = rule {
  OptWs ~ zeroOrMore(Node).separatedBy(Newline ~ OptWs) ~ OptWs
}
\end{verbatim}

Опциональные пробелы могут быть и перед списоком нод, и после него, и
между отдельными его элементами, поэтому у нас в правиле получилось так
много вхождений \texttt{MaybeWs}. Теперь определим имя блока --- это всё
тот же идентификатор, что используется и в имени ключа:

\begin{verbatim}
def BlockName = rule { Identifier }
\end{verbatim}

Наконец, всё необходимое для объявления блока целиком у нас есть,
поэтому объявим блок:

\begin{verbatim}
def Block = rule { BlockName ~ "{" ~ Nodes ~ "}" }
\end{verbatim}

Помните мы определяли \texttt{BlockBeginning} и \texttt{BlockEnding}?
Используем их в объявлении:

\begin{verbatim}
def Block = rule { BlockName ~ BlockBeginning ~ Nodes ~ BlockEnding }
\end{verbatim}

Заметьте, что \texttt{Block} ссылается на правило \texttt{Nodes},
которое будет ссылаться на правило Node. Node может ссылаться как на
правило Block, из-за чего возникает цикл. Поэтому нам необходимо явно
указать тип правила, успокоив Parboiled. Так как мы пишем
распознаватель, тип правила всегда будет Rule0 (подробнее о типах правил
будет в следующей статье).

Итак, у нас всё есть, не хватает только точки входа, или корня (root),
который тоже представляет собой ни что иное, как список узлов, для
которого у нас уже есть готовое правило. Используем его, не забыв учесть
возможные пробелы и завершить правило символом \texttt{EOI}:

\begin{verbatim}
def Root: Rule0 = rule { Nodes ~ EOI }
\end{verbatim}

Вот мы и написали распознаватель. Ознакомиться с его полным исходным
кодом вы можете
\href{https://gist.github.com/ppopoff/1bbf022327750f37ebcc}{здесь}.

Так как только лишь сопоставлять значения на практике приходится весьма
редко, а извлекать их из текста --- постоянно, в следующей статье я
расскажу вам захватывающие истории о том, как это делается, а также о
типах правил. В ней же мы и доведем наш распознаватель до состояния
полноценного парсера.

\section{Стек значений (Value
Stack)}\label{ux441ux442ux435ux43a-ux437ux43dux430ux447ux435ux43dux438ux439-value-stack}

Прежде чем извлекать какие-либо данные при помощи правил, следует
немного рассказать про одну из концепций, которая реализована в
Parboiled. Она называется Value Stack и ее можно не совсем корректно
перевести как «стек значений». Представляет он собой, действительно,
стек, который модифицируется \emph{действиями парсера} (parser actions),
в него помещаются и из него извлекаются результаты парсинга правил.
Именно этому стеку мы должны дать подсказку при объявлении рекурсивных
правил. Для того, чтобы элементы были помещены на стек, их необходимо
явно захватить, что отразится на виде ваших правил. Типы правил также
отражают количество захваченных элементов и их тип. Элементы стека могут
иметь разный тип, а типизация стека значений проверяется на этапе
компиляции.

\section{Типы
правил}\label{ux442ux438ux43fux44b-ux43fux440ux430ux432ux438ux43b}

В Parboiled2 существуют следующие типы правил:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{Rule0} --- просто отвечает на вопрос ``Сопоставилось ли?'', не
  изменяя содержимое стека.
\item
  \texttt{Rule1} --- помещает один объект в стек значений.
\item
  \texttt{Rule2} --- помещает два объекта в стек значений.
\item
  \texttt{RuleN} --- помещает N объектов в стек значений, используя
  семантику библиотеки Shapeless. Для работы с Parboiled2 знать
  Shapeless не нужно (хотя и будет полезно).
\item
  \texttt{PopRule} --- извлекает значения со стека, не помещая туда
  новых значений.
\end{itemize}

При желании можно объявить свои псевдонимы для типов, как это было в
Parboiled1. Так, например, в коде Parboiled2 реализуется \texttt{Rule2}:

\begin{verbatim}
type Rule2[+A, +B] = RuleN[A :: B :: HNil]
\end{verbatim}

В Parboiled1 для каждого количества аргументов от 0 до 7 существовал
отдельный тип, что создавало так называемую «проблему \texttt{Rule7}»:
класса \texttt{Rule8} уже нет и положить восемь элементов в стек
значений не получится, даже если очень хочется. Существуют различные
пути для обхода этой проблемы, и про один из них я расскажу в следующей
статье.

\section{Действия парсера (parser
actions)}\label{ux434ux435ux439ux441ux442ux432ux438ux44f-ux43fux430ux440ux441ux435ux440ux430-parser-actions}

Действия парсера стоило бы назвать действиями над стеком, так как они
позволяют извлекать данные из сопоставившихся правил, преобразовывать
их, а при условии высокой степени вашей испорченности --- производить с
ними сайд-эффекты (что может в некоторых случах быть действительно
необходимым, например, если размер и количество извлекаемых данных
заранее не известны). С помощью действий можно формировать абстрактные
синтаксические деревья
(\href{https://ru.wikipedia.org/wiki/Абстрактное_синтаксическое_дерево}{AST}),
их можно использовать для вычисления «на месте», как это сделано в
\href{calc}{примере с калькулятором}.

\section{Захватывающие
истории}\label{ux437ux430ux445ux432ux430ux442ux44bux432ux430ux44eux449ux438ux435-ux438ux441ux442ux43eux440ux438ux438}

Чтобы совершить какое-то полезное дейстие над данными, нам надо их
сначала захватить. Для этого существует функция \texttt{capture}: она
сопоставляет данные с правилом и в случае успеха помещает их на стек
значений.

Предположим у нас есть правило типа \texttt{Rule0}, из которого мы хотим
хоть что-то вытащить:

\begin{verbatim}
def User: Rule0 = rule { FirstName ~ Separator ~ LastName }
\end{verbatim}

Нам нужно решить, что именно мы будем захватывать, хоть и очевидно, что
разделитель не представляет никакой художественной ценности:

\begin{verbatim}
def User: Rule2[String, String] = rule {
  capture(FirstName) ~ Separator ~ capture(LastName)
}
\end{verbatim}

С этого момента наше правило уже не \texttt{Rule0}, а \texttt{Rule2},
так как оно захватывает и оправляет в стек значений две строки. Впрочем,
тип можно и не указывать, компилятор все поймет сам.

\subsection{Оператор действия
\textasciitilde{}\textgreater{}}\label{ux43eux43fux435ux440ux430ux442ux43eux440-ux434ux435ux439ux441ux442ux432ux438ux44f}

\ldots{} или оператор, которым вам придется пользоваться чаще всего. В
качестве правого параметра принимает лямбду, на вход которой отправляет
захваченные со стека объекты --- тем самым позволяя лямбде с этими
объектами работать. Потом, при желании, значения можно отправить обратно
в стек, или же создать из них узел для вашего AST --- выберите по своему
вкусу. В любом случае, для того, чтобы действие осуществилось, нужно
предварительно выполнить захват данных на стек при помощи функции
\texttt{capture}. В зависимости от типа возвращаемого значения
используются различные формы оператора
\texttt{\textasciitilde{}\textgreater{}}, что делает использование
данного оператора простым и интуитивным.

\begin{quote}
В Parboiled1 захват выполнялся неявно, что я нахожу весьма неудобным.
\end{quote}

Теперь немного подробнее про лямбду. Ее сигнатура зависит от количества
и типизации захваченных объектов, причем за раз лямбда может захватить
\href{https://github.com/sirthias/parboiled2/issues/85}{не более 22
аргументов}. Типы аргументов лямбды соответствуют типам значений,
снимаемых со стека, а типы возвращаемых значений --- типам значений,
помещаемых назад в стек.

Для примера попробуем извлечь у парсера хотя бы одно целое число:

\begin{verbatim}
def UnsignedInteger: Rule1[Int] = rule {
  capture(Digit.+) ~> (numStr => numStr.toInt)
}
\end{verbatim}

В этой ситуации поощряется использование фирменного скаловского
плейсходера:

\begin{verbatim}
def UnsignedInteger: Rule1[Int] = rule {
  capture(Digit.+) ~> (_.toInt)
}
\end{verbatim}

Здесь наша лямбда имеет тип \texttt{(String\ =\textgreater{}\ Int)}, что
обуславливает тип нашего правила - \texttt{Rule1{[}Int{]}}. Позволяется
применять оператор \texttt{\textasciitilde{}\textgreater{}} и к
типизированному правилу, например, следующее правило сопоставляет целое
число, но поместит в стек не его, а его удвоенное значение:

\begin{verbatim}
def TwoTimesLarger = rule { UnsignedInteger ~> (i => i * 2) }
\end{verbatim}

Тип правила \texttt{TwoTimesLarger} так и останется
\texttt{Rule1{[}Int{]}}, только на стеке будет лежать другое значение.

\begin{quote}
Явное указание типа аргументов лямбда-функции не самая лучшая идея (по
крайней мере, на момент написания статьи). В компиляторе Scala
существует весьма неприятный баг, который не даст вашему коду нормально
скомпилироваться.
\end{quote}

С одним аргументом мы разобрались, но что делать, если их несколько? Как
поведет себя лямбда? Просто и предсказуемо: первый параметр
соответствует самому верхнему значению на стеке, второй параметр ---
второму сверху, и так далее. Так как процедура захвата подвыражений
выполняется \emph{справа налево}, то порядок аргументов лямбда-функции
соответствует порядку записи операций захвата:

\begin{verbatim}
def UserWithLambda: Rule2[String, String] = rule {
  capture(FirstName) ~ Separator ~ capture(LastName) ~> ((firstName, lastName) => ...)
}
\end{verbatim}

Благодаря оператору действия мы можем уменьшать количество значений на
стеке:

\begin{verbatim}
def UserName = User ~> ((firstName, lastName) => s"$firstName $lastName")
\end{verbatim}

В приведенном примере исходный тип правила \texttt{User} был
\texttt{Rule2{[}String,\ String{]}}, применив к нему лямбда-функцию мы
создали новое правило \texttt{UserFirstName} с типом
\texttt{Rule1{[}String{]}}.

Лямбда не обязана принимать \emph{все} параметры со стека, можно
ограничиться последними N значениями (помним, что лямбда забирает
аргументы с конца стека):

\begin{verbatim}
(foo: Rule2[Int, String]) ~> (_.toDouble)
// bar: Rule2[Int, Double].
\end{verbatim}

Ничего не мешает нам попробовать скормить правилу лямбда-функцию, не
имеющую аргументов, с предсказуемым результатом:

\begin{verbatim}
(foo: Rule0) ~> (() => 42)
// bar: Rule1[Int].
\end{verbatim}

У Parboiled2 есть более мощные инструменты, например, возможность
вернуть из лямбды на стек сразу группу значений:

\begin{verbatim}
(foo: Rule1[Event]) ~> (e => e::DateTime.now()::"localhost"::HNil)
// bar: RuleN[Event::DateTime::String::HNil]
\end{verbatim}

Фактически мы конструируем фирменный шейплессовский \texttt{HList}. Тип
результирующего правила будет
\texttt{RuleN{[}Event::DateTime::String::HNil{]}}.

Аналогично можно забирать значения со стека значений, ничего не отдавая
взамен: для этого лямбда всего-навсего должна «возвращать» тип
\texttt{Unit}. Типом получившегося правила, как вы наверное догадались,
будет \texttt{Rule0}:

\begin{verbatim}
(foo: rule1[String]) ~> (println(_))
// bar: Rule0
\end{verbatim}

Кроме того, оператор действия предлагает особо сладкий сахар для
case-классов:

\begin{verbatim}
case class Person(name: String, age: Int)

(foo: Rule2[String, Int]) ~> Person
// bar: Rule1[Person]
\end{verbatim}

Правда нужно отметить, что компилятор может и не переварить этот сахар,
если для case-класса определен companion object. Тогда придется добавить
лямбду, немного подчеркиваний и записать:
\texttt{\textasciitilde{}\textgreater{}\ (Person(\_,\ \_))}.

Сахар для case-классов идеально подходит для построения AST, опытные
пользователи могут даже заметить, что в этом случае он работает
совершенно аналогично оператору
\texttt{\textasciitilde{}\textasciitilde{}\textgreater{}} из Parboiled1.
Существуют и другие способы применения
\texttt{\textasciitilde{}\textgreater{}} , но о них вы узнаете не от
меня, а из документации. Отмечу только, что оператор
\texttt{\textasciitilde{}\textgreater{}} реализуется в коде Parboiled2
весьма нетривиальным образом, но как бы сложно не выглядело его
определение, пользоваться им одно удовольствие. Пожалуй, самое лучшее
техническое решение, принятое на этапе создания DSL.

\subsection{run}\label{run}

Особая версия оператора действия для любителей острых ощущений. Для
программиста во многих отношениях \texttt{run} ведет себя точно так же,
как и \texttt{\textasciitilde{}\textgreater{}}, кроме того маленького
неудобства, когда в случае с \texttt{run} компилятор не выводит типы
автоматически и их приходится обозначать явно. Оператор является очень
удобным средством для создания непроверяемых сайд-эффектов, например как
здесь:

\begin{verbatim}
def RuleWithSideEffect = rule {
  capture(EmailAddress) ~ run { address: String => send(address, subj, message) } ~ EOI
}
\end{verbatim}

Типом результирующего правила будет \texttt{Rule0}, а сопоставленная
строка оказывается никому не нужна и ни в какой стек значений не
попадет, что иногда бывает необходимо. Пользователи Parboiled1 наверное
заметили, что в описанном выше контексте, \texttt{run} ведет себя так
же, как оператор \texttt{\textasciitilde{}\%}.

\begin{quote}
\textbf{Предупреждение:} При использовании сайд-эффектов, не стоит
заигрывать со стеком значений. Да, к нему можно получить прямой доступ,
но по ряду причин этого лучше не делать.
\end{quote}

\subsection{push}\label{push}

Функция \texttt{push} помещает данные на стек значений в случае, если
соответствующее ему правило сопоставилось. На практике мне не
приходилось пользоваться им часто, так как большую часть работы может
выполнить оператор \texttt{\textasciitilde{}\textgreater{}}, но
существует пример, в котором \texttt{push} просто блистает:

\begin{verbatim}
sealed trait Bool
case object True extends Bool
case object False extends Bool

def BoolMatch = rule { "true" ~ push(True) | "false" ~ push(False) }
\end{verbatim}

\begin{quote}
Хоть это нигде и не отмечено, данное правило следует семантике
call-by-name и вычисляется каждый раз, а значит и его аргумент
вычисляется каждый раз. Обычно это пагубно сказывается на
производительности, поэтому \texttt{push} лучше использовать с
константами и только c константами.
\end{quote}

Так же как в случае с \texttt{run} и
\texttt{\textasciitilde{}\textgreater{}}, тип значения, переданного в
\texttt{push}, определяет содержимое стека и тип создаваемого правила.

\subsection{Вложенные
парсеры}\label{ux432ux43bux43eux436ux435ux43dux43dux44bux435-ux43fux430ux440ux441ux435ux440ux44b}

В Parboiled2 существует поддежрка вложенных парсеров: захватывая текст и
скармливая его оператору \texttt{\textasciitilde{}\textgreater{}} мы
получаем переменную строкового типа в качестве параметра лямбда функции.
Проведя некоторые операции со сторокой мы можем скормить ее
какому-нибудь подпарсеру и так далее. На практике применять не
приходилось, но следует знать, что такая возможность есть.

\section{Генерация
AST}\label{ux433ux435ux43dux435ux440ux430ux446ux438ux44f-ast}

У нас есть все необходимые знания, чтобы написать свой парсер,
генерирующий синтактическое дерево. Синтаксические деревья строятся из
нод. Поэтому начнем с них, вернее с их описания:

\begin{verbatim}
sealed trait AstNode
case class KeyValueNode(key: String, value: String) extends AstNode
case class BlockNode(name: String, nodes: Seq[AstNode]) extends AstNode
\end{verbatim}

Каждый из кейс классов соответствует определенному типу ноды, вроде бы
все ясно и понятно. Тем не менее, давайте постараемся найти что-то общее
среди приведенных выше узлов. У каждого есть имя, просто в случае с
парой ключ-значение это ключ. Узлы между собой различать тоже как-то
нужно.

\begin{verbatim}
sealed trait AstNode {
  def name: String
}

case class KeyValueNode
(override val name: String, value: String) extends AstNode

case class BlockNode
(override val name: String, nodes: Seq[AstNode]) extends AstNode
\end{verbatim}

Начнем с узла для пар ключ-значение. Нам нужно захватить ключ, захватить
значение и собрать это все в case class посредством оператора
\texttt{\textasciitilde{}\textgreater{}}. Захват мы будем делать «на
месте» (в правилах для ключа и значения). И начнем мы с ключа:

\begin{verbatim}
// Можно довериться выводу типов и не указывать тип явно
def Key: Rule1[String] = rule { capture(oneOrMore(KeySymbol)) }
\end{verbatim}

Просто добавляем \texttt{capture} и все --- Parboiled думает о нас.
Строка будет отправлена на стек. А вот с захватом значения ситуация
сложнее. Если мы провернем операцию, аналогичную для ключа, нам придет
строка с кавычками. Они нам нужны? Поэтому захват будем делать на
территории строки:

\begin{verbatim}
def QuotedString: Rule1[String] = rule {
  '"' ~ capture(QuotedStringContent)  ~ '"'
}
\end{verbatim}

Для правила Value ничего делать не нужно, оно автоматически будет иметь
тип Rule1 (так как тело строки было захвачено ранее, со стека оно никуда
не ушло).

\begin{quote}
Захват \texttt{capture} нужно делать один раз. И желательно, в том
правиле, где он должен был произойти
\end{quote}

Теперь соберем case class:

\begin{verbatim}
def KeyValuePair: Rule1[AstNode] = rule {
  Key ~ MayBeWS ~ "=" ~ MayBeWS ~ Value ~> KeyValueNode
}
\end{verbatim}

Используем синтаксический сахар и элегантно упаковываем полученные ключ
и значение в подходящую ноду. Конечно мы можем использовать расширенный
лямбда-синтаксис и выполнить какие-либо преобразования. Но нам они не
нужны. Теперь разберемся со списком нод:

\begin{verbatim}
// тип должен быть объявлен явно, даже если вы полагаетесь на компилятор
def Node: Rule1[AstNode] = rule { KeyValuePair | Block }
\end{verbatim}

Так как каждая из нод захвачена, правило \texttt{Nodes} изменений не
требует, разве что стоит указать тип значения, помещаемого на стек:

\begin{verbatim}
def Nodes: Rule1[Seq[AstNode]] = rule {
  MayBeWS ~ zeroOrMore(Node).separatedBy(NewLine ~ MayBeWS) ~ MayBeWS
}
\end{verbatim}

У нас есть все для описания блочной ноды. Имя захватим на месте,
аналогично правилу для ключа:

\begin{verbatim}
def BlockName: Rule1[String] = rule { capture(oneOrMore(BlockNameSymbol.+)) }
\end{verbatim}

Ноды уже были захвачены, поэтому просто соберем данные в case class:

\begin{verbatim}
def Block: Rule1[AstNode] = rule {
  BlockName ~ MayBeWS ~ BlockBeginning ~ Nodes ~ BlockEnding ~> BlockNode
}
\end{verbatim}

Правило, которое описывает корень дерева, так же состоит из нод, поэтому
можно ничего больше и не делать. И вроде бы все работает хорошо и ничего
менять не хочется, однако результат выглядит не очень красиво: у нас
есть два типа нод, и корень который представляет список нод. И третий
явно лишний. Мы можем представить корень в качестве блока, с особым
именем.

\begin{verbatim}
def Root: Rule1[AstNode] = rule {
  Nodes ~ EOI ~> {nodes: Seq[AstNode] => BlockNode(RootNodeName, nodes)}
}
\end{verbatim}

Какое имя выбрать? Мы можем дать блоку вполне осознанное имя, например
root, но тогда нас могут ждать непредвиденные сюрпризы, если кто-то
захочет выбрать имя root. Зная что BlockName является идентификатором,
который не допускает ряд символов, можно попробовать имена вроде
\texttt{"\$root"}, \texttt{"!root!"} или \texttt{"\%root\%"}. Работать
будет. Я предпочту пустую строку:

\begin{verbatim}
val RootNodeName = ""
\end{verbatim}

Пустая строка:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Удовлетворяет главному требованию --- не является валидным именем
  блока или ключа;
\item
  Отлично подойдет если мы захотим расширить грамматику. Как бы мы не
  мучили парсер, уж что-что, а пустую строку пользователь точно не
  создаст.
\end{itemize}

Теперь у нас есть захваченные данные. Остается только выполнить прогон
из корня для подходящего текста.

\section{DSL для работы с
узлами}\label{dsl-ux434ux43bux44f-ux440ux430ux431ux43eux442ux44b-ux441-ux443ux437ux43bux430ux43cux438}

Получив на руки рабочий парсер, способный отдавать синтаксическое
дерево, мы должны с этим деревом как-то работать. Создание небольшого
DSL значительно упрощает эту задачу. Например, нам нужно перейти к
следующей ноде по имени. Можно каждый раз писать один и тот же код, а
можно сделать небольшой метод (продублированный перегруженным
оператором), способный возвращать следующую ноду. Ниже приведены
основные методы необходимые для работы с AstNode. На базе которых можно
сделать много других (наиболее подходящих под ваши нужды). Если
захотите, можно дать им символьные имена и любоваться красотой
полученного DSL.

\begin{verbatim}
/**
 * Код имеющий крайне опосредованное отношение к parboiled
 */
trait NodeAccessDsl { this: AstNode =>

  def isRoot = this.name == BkvParser.RootNodeName

  lazy val isBlockNode = this match {
    case _: KeyValueNode => false
    case _ => true
  }

  /**
   * В случае блокового узла возвращает список вложенных пар
   * ключ-значение
   */
  def pairs: Seq[KeyValueNode] = this match {
    case BlockNode(_, nodes) =>
      nodes collect { case node: KeyValueNode => node }
    case _ => Seq.empty
  }

  /**
   * В случае блокового узла возвращает спосок вложенных
   * блоков
   */
  def blocks: Seq[BlockNode] = this match {
    case BlockNode(_, nodes) =>
      nodes collect { case node: BlockNode => node }
    case _ => Seq.empty
  }

  /**
   * Значение в случае пары "ключ-значение"
   */
  def getValue: Option[String] = this match {
    case KeyValueNode(_, value) => Some(value)
    case _ => None
  }
}
\end{verbatim}

Хочу отметить, что лишних методов не бывает, и практически каждый раз
требуются: рекурсивный поиск, возможность изменять значения в нодах
(изменяя состояние, либо используя
\href{http://stackoverflow.com/questions/8307370/functional-lenses}{линзы}).
Наличие разнообразных вспомогательных методов, работающих с деревом,
очень сильно упрощает жизнь.

В итоге мы написали функциональный парсер, используя Parboiled2, и
сделали работу с получаемым синтаксическим деревом относительно
комфортной. В следующей статье я расскажу о дополнительных возможностях
библиотеки и о процессе оптимизации производительности. Также будет
рассмотрен процесс миграции с предыдущей версии. Расскажу о недостатках,
и о том как с этими недостатками жить.

С кодом парсера вы можете ознакомиться
\href{https://github.com/ppopoff/bkv-parser}{здесь}.

\section{Производительность}\label{ux43fux440ux43eux438ux437ux432ux43eux434ux438ux442ux435ux43bux44cux43dux43eux441ux442ux44c}

Parboiled2 работает быстро, но иногда он может работать еще быстрее. В
этом разделе мы поговорим о доступных микрооптимизациях. Главное при
выполнении оптимизаций --- своевременность. Но если есть возможность
сразу написать чуть более оптимальный код, не потеряв при этом в
выразительности --- этой возможностью обязательно следует
воспользоваться.

\subsection{\texorpdfstring{Разворачивайте \texttt{n.times} для малых n
\textless{}=
4}{Разворачивайте n.times для малых n \textless{}= 4}}\label{ux440ux430ux437ux432ux43eux440ux430ux447ux438ux432ux430ux439ux442ux435-n.times-ux434ux43bux44f-ux43cux430ux43bux44bux445-n-4}

Вы можете выиграть в производительности, если для малых \emph{n} вместо
оператора повторения \texttt{n.times} просто соедините несколько
повторяющихся правил в цепочку. Сколько повторений имеет смысл
разворачивать --- зависит от обстоятельств, но едва ли это число больше
четырех.

\begin{verbatim}
// Медленно
rule { 4 times Digit }

// Быстро
rule { Digit ~ Digit ~ Digit ~ Digit }
\end{verbatim}

Актуальность этой оптимизации
\href{https://github.com/sirthias/parboiled2/issues/101}{объявлена}
самим Матиасом, хотя, гипотетически, оператор \texttt{n.times} мог бы и
сам ее выполнять.

\subsection{\texorpdfstring{Ускорение операций со стеком для
\texttt{n.times}}{Ускорение операций со стеком для n.times}}\label{ux443ux441ux43aux43eux440ux435ux43dux438ux435-ux43eux43fux435ux440ux430ux446ux438ux439-ux441ux43e-ux441ux442ux435ux43aux43eux43c-ux434ux43bux44f-n.times}

Использование подобной техники позволит вам выжать немножко
производительности и при извлечении данных со стека значений. Например,
так ее можно применить к предыдущему правилу:

\begin{verbatim}
def Digit4 = rule {
  Digit ~ Digit ~ Digit ~ Digit ~
    push(
      #(charAt(-4))*1000 +
      #(charAt(-3))*100 +
      #(charAt(-2))*10 +
      #(lastChar)
    )
}
\end{verbatim}

\subsection{\texorpdfstring{Не пересоздавайте
\texttt{CharPredicate}}{Не пересоздавайте CharPredicate}}\label{ux43dux435-ux43fux435ux440ux435ux441ux43eux437ux434ux430ux432ux430ux439ux442ux435-charpredicate}

Совершенно нормально радоваться новым возможностям класса
\texttt{CharPredicate}, но создавать свои экземпляры типа
\texttt{CharPredicate} внутри блока \texttt{rule} совершенно не стоит:
ваш предикат будет пересоздаваться каждый раз, когда выполняется
правило, что драматически испортит производительность вашего парсера.
Поэтому, вместо того чтобы создавать символьные предикаты каждый раз,
определите их внутри вашего парсера как константу:

\begin{verbatim}
class MyParser(val input: ParserInput) extends Parser {
  val Uppercase = CharPredicate.from(_.isUpper)
  ...
}
\end{verbatim}

или, что еще лучше, отправьте это объявление в объект-компаньон вашего
парсера:

\begin{verbatim}
class MyParser(val input: ParserInput) extends Parser {
  ...
}

object MyParser {
  val Uppercase = CharPredicate.from(_.isUpper)
}
\end{verbatim}

\subsection{Используйте семантические
предикаты}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-ux441ux435ux43cux430ux43dux442ux438ux447ux435ux441ux43aux438ux435-ux43fux440ux435ux434ux438ux43aux430ux442ux44b}

Особенность данных правил состоит в том, что они не взаимодействуют со
стеком значений. Подробно, они описаны в документации, но вот самое
главное, что вы должны о них знать:

\begin{quote}
При использовании семантических предикатов парсер не совершает
прогресса, то есть не перемещает свой курсор на следующий символ.
Поэтому при их бездумном использовании парсер может зациклиться.
\end{quote}

Помните пример с объявлением символьного предиката для символов верхнего
регистра? Вы можете сделать тоже самое, используя семантический предикат
\texttt{test}:

\begin{verbatim}
def JavaUpperCase = rule { oneOrMore(test(currentChar.isUpper) ~ ANY) }
\end{verbatim}

\subsection{\texorpdfstring{Используйте \texttt{ANY} там, где хотели бы
видеть
\texttt{CharPredicate.All}}{Используйте ANY там, где хотели бы видеть CharPredicate.All}}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-any-ux442ux430ux43c-ux433ux434ux435-ux445ux43eux442ux435ux43bux438-ux431ux44b-ux432ux438ux434ux435ux442ux44c-charpredicate.all}

Увы, \texttt{CharPredicate.All} работает медленно для больших диапазонов
символов, \texttt{ANY} работает быстрее. Воспользуйтесь этим знанием.

\subsection{Используйте инвертирующий
предикат}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-ux438ux43dux432ux435ux440ux442ux438ux440ux443ux44eux449ux438ux439-ux43fux440ux435ux434ux438ux43aux430ux442}

Представьте, что ваш парсер должен захватывать все символы до перевода
строки (для определенности, в стиле Unix). Конечно, это можно сделать
при помощи \texttt{noneOf}, но инвертирующий предикат будет быстрее:

\begin{verbatim}
def foo = rule { capture(zeroOrMore(noneOf("\n"))) }

// Быстрее?
def foo = rule { capture(zeroOrMore(!'\n')) }
\end{verbatim}

К сожалению, этот замечательно выглядящий пример зациклит, потому что
парсер не будет совершать прогресса. Чтобы это исправить, необходимо
правило, передвигающее курсор парсера, но при этом не изменяющее стек.
Например, вот такое:

\begin{verbatim}
def foo = rule { capture(zeroOrMore( !'\n' ~ ANY )) }
\end{verbatim}

Теперь правило \texttt{foo} поглотит абсолютно все, кроме \texttt{EOI} и
перевода строки.

\section{Отчеты об
ошибках}\label{ux43eux442ux447ux435ux442ux44b-ux43eux431-ux43eux448ux438ux431ux43aux430ux445}

Не думаю, что вам захочется работать с парсером, выдающим бессмысленные
сообщения при любых некорректных входных данных. Parboiled2 способен
вполне внятно рассказывать об ошибках, если вы ему в этом поможете.

\subsection{Форматирование}\label{ux444ux43eux440ux43cux430ux442ux438ux440ux43eux432ux430ux43dux438ux435}

Итак, если что-то навернулось, парсер передаст в ваше распоряжение
объект типа \texttt{ParseError}, который можно привести в читаемый вид
посредством метода \texttt{formatError}:

\begin{verbatim}
val errorMessage = parser formatError error
\end{verbatim}

Если форматирование по умолчанию вас по каким-то причинам не устраивает,
свои пожелания следует передать парсеру явным образом:

\begin{verbatim}
val errorMessage parser.formatError(error, new ErrorFormatter(showTraces = true))
\end{verbatim}

Если вы захотите написать свой \texttt{ErrorFormatter}, вам придется
самостоятельно разобраться со структурой класса \texttt{ParseError},
который объявлен в глубине Parboiled таким образом:

\begin{verbatim}
case class ParseError(position: Position, charCount: Int, traces: Seq[RuleTrace]) extends RuntimeException
\end{verbatim}

Также стоит отметить наличие нескольких схем доставки сообщений об
ошибке до пользователя: по вашему желанию \texttt{ParseError} может быть
представлен не только в виде объекта \texttt{Try}, а, например, в виде
полиморфного типа или \texttt{Either}. Подробнее можно ознакомиться
\href{https://github.com/sirthias/parboiled2/blob/master/README.rst\#alternative-deliveryschemes}{здесь}.

\begin{verbatim}
def Foo = rule { "foo" | fail("Я упаль!") }
\end{verbatim}

\subsection{Тонкая
настройка}\label{ux442ux43eux43dux43aux430ux44f-ux43dux430ux441ux442ux440ux43eux439ux43aux430}

Существует опция, позволяющая обойти встроенный механизм формирования
сообщений об ошибках. Для этого нужно использовать правило \texttt{fail}
с сообщением, которое вы хотите увидеть в случае ошибки:

\begin{verbatim}
def Goldfinger = rule { "talk" | fail("to die") }
\end{verbatim}

Тогда при удобном случае вы получите назад свое сообщение об ошибке
примерно в такой форме:

\begin{verbatim}
Invalid input 'Bond', expected to die. (line 1, column 1):
\end{verbatim}

\subsection{Именованные
правила}\label{ux438ux43cux435ux43dux43eux432ux430ux43dux43dux44bux435-ux43fux440ux430ux432ux438ux43bux430}

Использование подобного типа правил бывает весьма полезным не только в
целях отлова ошибок. Данный механизм подробно описан в разделе «Best
Practices».

\subsection{atomic}\label{atomic}

Parboiled2 генерирует парсеры, основанные на PEG. Это означает, что
парсеры оперируют символами, а не строками (как многие могли подумать),
поэтому и ошибки вам будут показываться на символьном уровне.
Согласитесь --- сообщение вида «У вас тут X, мы ожидали Y или Z»
потребует больше мысленных усилий, чем «У вас тут XX, а мы ожидали
увидеть XY или XZ». Для того, чтобы видеть строки в отчетах об ошибках
целиком, существует маркер \texttt{atomiс}, всего-то и нужно обернуть в
него правило:

\begin{verbatim}
def AtomicRuleTest = rule { atomic("foo") | atomic("fob") | atomic("bar") }
\end{verbatim}

Чтобы при лисичках (\texttt{foxes}) на входе получить

\begin{verbatim}
Invalid input "fox", expected "foo", "fob" or "bar" (line 1, column 1):
foxes
^
\end{verbatim}

\subsection{quiet}\label{quiet}

Когда вариантов для выбора слишком много, не всегда хочется уведомлять
пользователя о всех возможных альтернативах. Например, в определенном
месте ваш парсер ожидает множество пробельных символов в совокупности с
неким правилом. Для устранения избыточности в отчете, вы, возможно,
захотите умолчать о пробелах. С использованием маркера \texttt{quiet}
это очень просто:

\begin{verbatim}
def OptionalWhitespaces = rule { quiet(zeroOrMore(anyOf(" \t\n"))) }
\end{verbatim}

Честно признаюсь --- ситуаций, поощряющих использования этого правила, я
не встречал. Так же, как и \texttt{atomic}, оно подробно
\href{https://github.com/sirthias/parboiled2/blob/master/README.rst\#the-quiet-marker}{описано
в документации}.

\subsection{Восстановление после
ошибок}\label{ux432ux43eux441ux441ux442ux430ux43dux43eux432ux43bux435ux43dux438ux435-ux43fux43eux441ux43bux435-ux43eux448ux438ux431ux43eux43a}

Практически единственный эпизод, где Parboiled1 выигрывает, а у
Parboiled2 дела обстоят не очень хорошо: парсер падает уже только от
вида первой же встреченной им ошибки. Для большинства сценариев это
отлично подходит: это, например, не мешает парсить логи, текстовые
протоколы, конфигурационные файлы (для ряда случаев), однако
разработчикам DSL или IDE-подобных инструментов такое положение дел
будет не по душе.
\href{https://github.com/sirthias/parboiled2/issues/42}{Матиас обещает
это исправить}, поэтому если вам эта функциональность очень сильно нужна
уже сегодня --- напишите на баг-трекер, возможно это ускорит процесс
разработки.

В Parboiled1 имеется
\href{https://github.com/sirthias/parboiled/wiki/Parse-Error-Handling}{огромное
число ParserRunnerов} на все случаи жизни. Посмотрите в сторону
\texttt{RecoveringParserRunner}, если вам нужно продолжать парсинг в
случае ошибок.

\subsection{Тестирование}\label{ux442ux435ux441ux442ux438ux440ux43eux432ux430ux43dux438ux435}

Разработчики Parboiled используют для тестирования фреймворк
\href{https://etorreborre.github.io/specs2/}{specs2}, который они
дополнили своим вспомогательным классом
\href{http://bit.ly/1Y5iZ9t}{TestParserSpec}. Он покажется неудобным
тем, кто использует scalatest, но основную его идею можно и перенять. По
секрету от Матиаса, его решение не отличается особенной аккуратностью,
так как полагается на изменяемое состояние. Возможно, в будущем нас
будет ждать что-то похожее на полноценный каркас для тестирования.

Правила можно тестировать как по отдельности, так и вместе. Лично я
предпочитаю писать тесты не на каждое правило, а проверять только
главное правило в «особых» случаях:

\begin{quote}
Во многих форматах, даже стандартизованных, могут встречаться весьма
интересные моменты. Например, в BSD-подобном формате сообщений
\href{https://www.ietf.org/rfc/rfc3164.txt}{RFC 3164} под число месяца
\emph{всегда} отводится две позиции, даже если само число имеет один
разряд. Вот пример из самого RFC:

\begin{quote}
If the day of the month is less than 10, then it MUST be represented as
a space and then the number. For example, the 7th day of August would be
represented as \texttt{"Aug\ \ 7"}, with two spaces between the
\texttt{"g"} and the \texttt{"7"}.
\end{quote}
\end{quote}

Помимо подобного рода «интересных моментов» можно скармливать правилу
строки с незакрытыми скобками, недопустимыми символами, проверять
порядок операций со стеком значений.

В тестировании есть еще одна тонкость, с которой вы сразу же
столкнетесь. Предположим, вы хотите оттестировать следующее правило:

\begin{verbatim}
def Decimal: Rule0 = rule {
  ("+" | "-").? ~ Digit.+ ~ "." ~ Digit.+
}
\end{verbatim}

Для этого отправим парсеру заведомо некорректный ввод и будем ждать на
выходе ошибку:

\begin{verbatim}
// Я еще не видел десятичных дробей с двумя разделителями.
val p = new MyParser("12.3.456").Decimal.run()  // Success(())
p.isFailure shouldBe true  // тест упадет
\end{verbatim}

Но при прогоне теста окажется, что парсер вернул удачный результат.
Почему так? В нашем правиле нет \texttt{EOI}, но если если мы добавим в
него \texttt{EOI}, то испортим все правила, которые используют
\texttt{Decimal}. Поэтому придется создать специальное тестирующее
правило, например, при помощи хитрого механизма
\href{https://github.com/sirthias/parboiled2/blob/master/README.rst\#advanced-techniques}{мета-правил}.
Давайте добавим EOI в конце нашего предыдущего примера, и убедимся в
том, что парсер упал с ошибкой:

\begin{verbatim}
Failure(ParseError(Position(5,1,6), Position(5,1,6), <2 traces>))
\end{verbatim}

\section{Недостатки
Parboiled}\label{ux43dux435ux434ux43eux441ux442ux430ux442ux43aux438-parboiled}

\subsection{Parboiled2}\label{parboiled2}

Если недостатки есть у людей, почему бы их не иметь библиотекам? Здесь
Parboiled2 не является исключением.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Длинные, слишком общие и совершенно непонятные сообщения компилятора
  об ошибках, в лучших традициях C++. Наглядный пример приведен на
  рисунке ниже (в правиле нечаянно пропущен оператор
  \texttt{\textasciitilde{}}). Причина связана с выполнением продвинутых
  проверок на типах, которые
  \href{https://github.com/sirthias/parboiled2/issues/106}{обещают
  убрать} в будущих версиях.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics{https://hsto.org/getpro/habr/post_images/ca6/fe6/0a4/ca6fe60a4692d96f4d7e2034bc4eaa0c.png}
\caption{Компилятор грязно ругается}
\end{figure}

\begin{itemize}
\item
  Эта проблема относится больше не к Parboiled2, а к scalac. Компилятору
  может снести крышу, если у лямбды, захватывающей значения со стека,
  явно (не)определены типы аргументов:

\begin{verbatim}
// Может не сработать
def MyRule = rule { oneOrMore(Visible) ~> {s => "[" + s + "]"} }

// Скорее всего сработает
def MyRule = rule { oneOrMore(Visible) ~> {s: String => "[" + s + "]"} }
\end{verbatim}

  Что сработает, а что нет --- зависит от версии вашего компилятора.
\item
  Многие IDE еще не научились поддерживать макровыражения, а Parboiled2
  был построен не без их помощи. Поэтому не стоит верить подчеркиваниям
  вашей среды разработки. Однажды я, забыв об этом, потратил целый день
  на поиск несуществующей ошибки буквально на ровном месте.
\item
  Отсутствие механизма восстановления при неудачном разборе.
  Проектирующих предметно-ориентированные языки, или же тех, кто хочет
  использовать Parboiled2 в качестве фронтэнда к своему компилятору, это
  сильно разочарует. Но над этим
  \href{https://github.com/sirthias/parboiled2/issues/42}{работают}.
  Если вы хотите видеть эту возможность --- пишите, это ускорит
  разработку.
\item
  Я думаю, что многим разработчикам своих небольших IDE и текстовых
  редакторов хотелось бы видеть более гибкие сообщения об ошибках, чем
  те, что предоставляются сейчас. На данный
  \href{https://github.com/sirthias/parboiled2/issues/96}{момент}
  существует всего два способа повлиять на них:

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    именованные правила,
  \item
    именованные вложенные правила.
  \end{itemize}
\end{itemize}

\subsection{Parboiled1}\label{parboiled1}

Большинство проектов все еще написаны на Parboiled1, и вряд-ли что-то
изменится резко и кардинально (в энтерпрайзе), поэтому может быть
полезным знать, как научиться мириться с его недостатками, коих у
Parboiled1 немало. Помимо весьма ограниченного DSL, у Parboiled
существует проблема «Rule8», которая усложняет написание парсера для
логов. Parboiled1 построен так, что на каждое правило с N элементами
имеется по классу, по аналогии со скаловскими кортежами (tuples): есть
\texttt{Rule0}, \texttt{Rule1}, вплоть до \texttt{Rule7}. Этого вполне
достаточно, чтобы распарсить сложные языки программирования, такие как
Java, да и вообще не вызывает существенных проблем при разборе
древовидных структур. А вот если нужно извлечь данные из линейной
структуры, например, сообщения лога-файла, то в это ограничение очень
несложно упереться. Решается это использованием кортежа вместо одного
результирующего правила. Вот пример:

\begin{verbatim}
def Event: Rule1[LogEvent] = rule {
  Header ~ " " ~ UserData ~ " " ~ Message ~~> {
    (header, data, message) => SyslogEvent (
      header._1, header._2, header._3, header._4, header._5, data._1, data._2, message
    )
  }
}
\end{verbatim}

Пусть выглядит убого, зато проблема решена.

\section{Best practices}\label{best-practices}

В этом разделе я расскажу о прописных истинах, работающих для любого
комбинатора парсеров, а так же о нюансах, специфичных для Parboiled2.

\subsection{CharUtils}\label{charutils}

Есть один полезный объект, не затронутый в документации:
\href{http://bit.ly/1NJJ2kd}{CharUtils}. Он содержит ряд статических
методов, способных облегчить вашу жизнь, например: изменение регистра
символов, экранирование, преобразование целочисленных значений в
соответствующие им символы (строки). и др. Его использование, возможно,
сэкономит ваше время.

\subsection{Пишите модульные
тесты}\label{ux43fux438ux448ux438ux442ux435-ux43cux43eux434ux443ux43bux44cux43dux44bux435-ux442ux435ux441ux442ux44b}

Одно небольшое неудачное изменение может сломать вам грамматику и
обеспечить острую ректальную боль. Это банальный совет, которым многие
пренебрегают. Парсер не так сложно протестировать, как, скажем IO: вам
не нужны Mock-объекты и другие ухищрения для этой рутинной, но очень
ценной работы. У нас была целая инфраструктура парсеров. И поверьте,
первое, что я делал при поиске ошибок --- садился и писал тесты, в
случае их отсутствия.

\subsection{Делайте парсеры и правила
маленькими}\label{ux434ux435ux43bux430ux439ux442ux435-ux43fux430ux440ux441ux435ux440ux44b-ux438-ux43fux440ux430ux432ux438ux43bux430-ux43cux430ux43bux435ux43dux44cux43aux438ux43cux438}

Разделяйте ваши парсеры на подпарсеры. Каждый компонент должен делать
что-то вполне определенное. Например если вы парсите LogEvent, у
которого определено поле Timestamp (особенно если этот Timestamp
соответствует какому-нибудь Rfc),то не поленитесь и вынесите его
отдельно.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Во-первых, это уменьшит код вашего основного прасера, и сделает его
  нагляднее.
\item
  Во-вторых, это заметно облегчит тестирование. Вы покроете модульными
  тестами ваш подпарсер. А после этого приступите к разработке главного
  парсера
\end{itemize}

Существуют разные подходы:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Разбивать парсер на трейты и использовать self-typed reference
  (предпочитаю этот способ).
\item
  Объявлять парсеры как самостоятельные сущности и использовать
  композицию.
\item
  Использовать встроенный механизм для создания subParsers.
\end{itemize}

Правила должны быть максимально компактными, но не компактней. Чем
меньше ваши правила, тем легче найти ошибку в грамматике. Очень сложно
понять логику разработчика, если он делает правила длинными, и при этом
многократно использует \texttt{capture}. Усугублять ситуацию может
неявный захват. Указание типа правила также помогает при поддержке.

\subsection{Отправляйте case objects вместо строк в Value
stack}\label{ux43eux442ux43fux440ux430ux432ux43bux44fux439ux442ux435-case-objects-ux432ux43cux435ux441ux442ux43e-ux441ux442ux440ux43eux43a-ux432-value-stack}

Данный совет можно отнести и к оптимизациям, так как это заставит парсер
работать быстрее. Отправляйте в Value stack значимые объекты, а не
строки. Это сделает ваш парсер быстрее, а код нагляднее.

Плохо:

\begin{verbatim}
def logLevel = rule {
  capture("info" | "warning" | "error") ~ ':’
}
\end{verbatim}

Хорошо:

\begin{verbatim}
def logLevel = rule {
    “info:”   ~ push(LogLevel.Info)
  | “warning" ~ push(LogLevel.Warning)
  | “error"   ~ push(LogLevel.Error)
}
\end{verbatim}

\subsection{Используйте упрощенный синтаксис для сборки
объекта}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-ux443ux43fux440ux43eux449ux435ux43dux43dux44bux439-ux441ux438ux43dux442ux430ux43aux441ux438ux441-ux434ux43bux44f-ux441ux431ux43eux440ux43aux438-ux43eux431ux44aux435ux43aux442ux430}

Этот красивый способ появился еще в Parboiled1. Никакой магии, просто
конструктор case classа вызывается неявно. Главное, чтобы количество и
тип аргументов, помещаемых на Value Stack, совпадали с сигнатурой
конструктора case classа.

Плохо:

\begin{verbatim}
def charsAST: Rule1[AST] = rule { capture(Characters) ~> ((s: String) => AText(s)) }
\end{verbatim}

Хорошо:

\begin{verbatim}
def charsAST = rule { capture(Characters) ~> AText }
\end{verbatim}

\subsection{Именованные правила (named
rules)}\label{ux438ux43cux435ux43dux43eux432ux430ux43dux43dux44bux435-ux43fux440ux430ux432ux438ux43bux430-named-rules}

Именованные правила заметно упрощают жизнь при получении отчетов об
ошибках, так как дают возможность вместо невнятного имени правила
использовать псевдоним. Или же помечать правила определенным тегом ---
«Это выражение» или «Модифицирует стек». В любом случае знать о данной
функции будет полезно.

Многие пользователи Parboiled1 уже полюбили эту возможность. Например
разработчики Neo4J, использующие Parboiled для разбора языка
\href{http://neo4j.com/docs/2.2.3/cypher-introduction.html}{Cypher}.

Как это выглядит в Parboiled1:

\begin{verbatim}
def Header: Rule1[Header] = rule("I am header") { ... }
\end{verbatim}

В Parboiled2:

\begin{verbatim}
def Header: Rule1[Header] = namedRule("header is here") { ... }
\end{verbatim}

Так же есть возможность давать имена вложенным правилам:

\begin{verbatim}
def UserName = rule { Prefix ~ oneOrMore(NameChar).named("username") ~ PostFix }
\end{verbatim}

\section{Миграция}\label{ux43cux438ux433ux440ux430ux446ux438ux44f}

Миграция --- процесс, чаще всего, несложный, но времени отнимает немало.
Поэтому я постараюсь хотя бы немного сэкономить драгоценные часы вашей
жизни и описать основные подводные камни.

\subsection{Classpath}\label{classpath}

Для того, чтобы избежать конфликтов с первой версией, Parboiled2
использует classpath \texttt{org.parboiled2} (тогда как classpath для
первой версии \texttt{org.parboiled}). Мавеновский \texttt{groupId},
однако, остался старым: \texttt{org.parboiled}. Благодаря этому, можно
иметь обе зависимости в одном проекте и осуществлять постепенный переход
на новую версию. Что, кстати, работает весьма неплохо при наличии
нескольких автономных парсеров. Если же ваши парсеры состоят из
множества модулей, переиспользуемых в разных местах (как это было в моем
случае) --- вам придется делать миграцию сразу и для всех модулей.

\subsection{Проверка
тестов}\label{ux43fux440ux43eux432ux435ux440ux43aux430-ux442ux435ux441ux442ux43eux432}

Убедитесь в наличии и работоспособности модульных тестов. Они же у вас
есть? Нет? Напишите их. В процессе миграции мне приходилось уточнять
некоторые грамматики из-за того, что новый DSL стал мощнее, и нечаянные
изменения ломали грамматики. Падающие тесты экономили много времени. С
серьезными проблемами, вроде поломки всей грамматики целиком, при
миграции я не сталкивался. Может быть кто-то поделится опытом, если с
ним это произошло.

\subsection{Код вокруг
парсера}\label{ux43aux43eux434-ux432ux43eux43aux440ux443ux433-ux43fux430ux440ux441ux435ux440ux430}

Теперь парсер будет пересоздаваться каждый раз, что не всегда удобно. С
PB1 я очень любил создавать парсер единожды, а потом многократно его
использовать. Теперь этот номер не пройдет. Поэтому вам придется
изменить конструктор парсера и немного переписать использующий его код,
и не бойтесь, что это ухудшит производительность.

\begin{quote}
\textbf{Предупреждение} Parboiled1 позволяет генерировать правила во
время выполнения. Поэтому если у вас имеется подобный персер, то вам,
скорее всего, придется его переписать: Parboiled2 использует
макровыражения которые делают динамику весьма затруднительной, взамен
давая лучшую производительность.
\end{quote}

\subsection{Композиция}\label{ux43aux43eux43cux43fux43eux437ux438ux446ux438ux44f}

Подход к композиции элементов парсера не изменился, это хорошая новость
для мигрирующих. Однако \texttt{Parser} теперь не трейт, а абстрактный
класс. Трейты (traits) --- удобнейшее средство композиции програмных
компонентов, в PB1 это позволяло подмешивать \texttt{Parser} в любые
модули, смешивая модули между собой. Изменение в пользу абстрактного
класса на эту возможность никак не повлияло, но теперь для этого нужно
использовать
\href{http://docs.scala-lang.org/tutorials/tour/explicitly-typed-self-references.html}{self-typed
reference}:

\begin{verbatim}
trait Numbers { this: Parser =>
  // Ваш код
}
\end{verbatim}

Тем, кто подобную возможность языка не использовал и каждый раз
подмешивал трейт \texttt{Parser}, придется изменить свои вкусовые
предпочтения.

В качестве альтернативного способа, вы можете сделать из ваших трейтов
полноправные парсеры и импортировать из них нужные правила (как методы)
в ваш основной парсер. Я, правда, все равно предпочитаю использовать
композиции трейтов, потому как нахожу их более наглядными: мне понятней
видеть парсер собранный из кусков, вместо множественных импортов.

\subsection{Избавляемся от
примитивов}\label{ux438ux437ux431ux430ux432ux43bux44fux435ux43cux441ux44f-ux43eux442-ux43fux440ux438ux43cux438ux442ux438ux432ux43eux432}

В процессе миграции обязательно устройте ревизию своей личной
библиотечки примитивных правил: удалите все что имеется в
\texttt{CharPredicate}. Ваша библиотечка похудеет, однако не исчезнет
совсем. Многие хотели бы добавить в parboiled поддержку различных
форматов дат, грамматику описывающую электронную почту, заголовки HTTP.
Parboiled просто комбинатор парсеров: он таковым был, таким и останется.
Однако согласитесь, что выбрасывать старый код очень приятно.

\section{Заключение}\label{ux437ux430ux43aux43bux44eux447ux435ux43dux438ux435}

В этой серии статей я попытался рассказать вам про самый прогрессивный и
перспективный инструмент парсинга, существующий для языка scala. Сделал
небольшой туториал и рассказал о проблемах, с которыми мне пришлось
столкнуться на практике. Надеюсь, что эта статья в худшем случае
окажется для вас полезной, а в лучшем --- станет руководством к
действию.

\section{Использованные
источники}\label{ux438ux441ux43fux43eux43bux44cux437ux43eux432ux430ux43dux43dux44bux435-ux438ux441ux442ux43eux447ux43dux438ux43aux438}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \href{https://groups.google.com/forum/\#!topic/parboiled-user/Ygb_M6XU5P8}{Список
  рассылки проекта Parboiled}
\item
  \href{http://www.youtube.com/watch?v=qZg4D62K4aQ}{Презентация
  Александра Мыльцева} и
  \href{http://myltsev.name/ScalaDays2014/\#/}{слайды к ней}
\item
  \href{http://bit.ly/1H2ZQ3A}{Примеры кода из репозитория Parboiled}
\item
  \href{https://github.com/sirthias/parboiled2/tree/master/scalaParser/src}{Парсер
  языка scala, написаный при помощи Parboiled2}
\end{itemize}
\section{Про Parboiled}\label{ux43fux440ux43e-parboiled}

\textbf{Часть 1. Почему Parboiled?}

Сегодня, в свете бурного роста популярности функциональных языков
программирования, всё чаще находят себе применение комбинаторы парсеров
--- инструменты, облегчающие разбор текста простым смертным. Такие
библиотеки, как \href{https://wiki.haskell.org/Parsec}{Parsec} (Haskell)
и \href{https://bitbucket.org/camlspotter/planck}{Planck} (OCaml) уже
успели хорошо себя зарекомендовать в своих экосистемах. Их удобство и
возможности в своё время подтолкнули создателя языка Scala, Мартина
Одерски, внести в стандартную библиотеку их аналог ---
\href{https://github.com/scala/scala-parser-combinators}{Scala Parser
Combinators} (ныне вынесены в
\href{http://mvnrepository.com/artifact/org.scala-lang.modules}{scala-modules}),
а знание и умение пользоваться подобными инструментами --- отнести к
обязательным требованиям к Scala-разработчикам
\href{http://www.scala-lang.org/old/node/8610}{уровня A3}.

Эта серия статей посвящена библиотеке
\href{https://github.com/sirthias/parboiled}{Parboiled} --- мощной
альтернативе и возможной замене для Scala Parser Combinators. В ней мы
подробно рассмотрим работу с текущей версией библиотеки --- Parboiled2,
а также уделим внимание Parboiled1, так как большая часть существующего
кода всё ещё использует именно её.

\textbf{Структура цикла:}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Часть 1. Почему Parboiled?
\item
  Часть 2. Сопоставление текста
\item
  Часть 3. Извлечение данных
\item
  Часть 4. Суровая действительность
\end{itemize}

\section{Введение}\label{ux432ux432ux435ux434ux435ux43dux438ux435}

Parboiled --- библиотека, позволяющая с легкостью разбирать (парсить)
языки разметки (такие как HTML, XML или JSON), языки программирования,
конфигурационные файлы, логи, текстовые протоколы и вообще что угодно
текстовое. Parboiled придётся весьма кстати, если вы захотите
разработать свой предметно-ориентированный язык
(\href{https://en.wikipedia.org/wiki/Domain-specific_language}{DSL}): с
её помощью вы сможете быстро получить
\href{https://en.wikipedia.org/wiki/Abstract_syntax_tree}{абстрактное
синтаксическое дерево} и, вспомнив паттерн
\href{https://en.wikipedia.org/wiki/Interpreter_pattern}{интерпретатор},
исполнять команды вашего доменного языка.

На данный момент существует несколько версий данной библиотеки:

\begin{itemize}
\item
  Parboiled for Java --- самая первая версия библиотеки. Написана
  Маттиасом Доеницем (Matthias Doeniz) на Java и для Java. До сих пор
  пользуется популярностью, хоть и находится в состоянии «end of life».
  Если по воле случая она досталась вам в наследство, или же вы
  сознательно начинаете проект на Java, советую рассмотреть в качестве
  альтернативы \href{https://github.com/fge/grappa}{grappa} --- форк
  Parboiled1, который старательно поддерживается в работоспособном
  состоянии пользователем с ником \href{https://github.com/fge}{fge}.
\item
  Parboiled --- библиотека, теперь уже более известная как Parboiled1,
  появилась на свет после того, как Маттиас проникся скалой. Он сделал
  Scala-фронтэнд для Parboiled, заодно забросив поддержку Java-версии. С
  выходом Parboiled2 потихонечку перестает поддерживаться и Scala-версия
  Parboiled1, однако не смотря на это, списывать её со счетов пока что
  не стоит:

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    Parboiled2 пока что не научился всем фичам Parboiled1;
  \item
    Parboiled1 всё ещё используется гораздо шире, чем Parboiled2,
    поэтому если вас внезапно перебросят на какой-нибудь старый
    Scala-проект, высок шанс столкнуться именно с ним.
  \end{itemize}
\item
  Parboiled2 --- новейшая версия библиотеки, устраняющая ряд недостатков
  PB1. Работает быстрее и, что самое главное, поддерживается
  разработчиками.
\end{itemize}

Я писал эту статью с упором на Parboiled2 (кстати, дальше я буду писать
о нём в мужском роде, без слова «библиотека»), но иногда я буду
отвлекаться, чтобы рассказать о важных отличиях между первой и второй
версиями.

\subsection{Основные
возможности}\label{ux43eux441ux43dux43eux432ux43dux44bux435-ux432ux43eux437ux43cux43eux436ux43dux43eux441ux442ux438}

Краткая характеристика Parboiled2:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Следует принципам
  \href{https://en.wikipedia.org/wiki/Parsing_expression_grammar}{PEG}.
\item
  Генерирует однопроходные парсеры. Отдельный лексер не требуется.
\item
  Используется типобезопасный DSL, являющийся подмножеством языка Scala.
\item
  Оптимизации выполняются на этапе компиляции.
\end{itemize}

На практике это означает:

\begin{itemize}
\item
  Вам не нужно писать парсер голыми руками.
\item
  Читаемость, сравнимая с лучшими сортами BNF (по-моему, PB даже круче).
\item
  Можно использовать всю мощь PEG и свободно разбирать рекурсивные
  структуры данных, в то время как регулярные выражения не могут этого
  \href{https://en.wikipedia.org/wiki/Chomsky_hierarchy\#The_hierarchy}{по
  определению}. Да, регулярными выражениями вы не распарсите ни JSON, ни
  даже простейшее арифметическое выражение, что уж говорить о языках
  программирования. На StackOverflow есть
  \href{http://stackoverflow.com/a/1733489/1447225}{небезызвестная
  цитата в тему}:

  \begin{quote}
  Asking regexes to parse arbitrary HTML is like asking Paris Hilton to
  write an operating system.
  \end{quote}
\end{itemize}

\begin{itemize}
\item
  Даже если вам нужно разобрать линейную структуру, Parboiled2 (при
  использовании должных оптимизаций) будет работать быстрее регулярных
  выражений. Доказательства приведены в следующем разделе.
\item
  В отличие от генераторов парсеров, таких как
  \href{http://www.antlr.org/}{ANTLR}, вы освобождены от мороки с
  раздельной генерацией кода и последующей его компиляцией. Весь код с
  Parboiled пишется на Scala, поэтому вы получаете подсветку синтаксиса
  и проверку типов из коробки, так же как и отсутствие дополнительных
  операций над файлами грамматик, в то время как парсер, сгенерированный
  ANTLR, будет иметь две фазы синтаксического разбора. Правда, несмотря
  на это, ANTLR всё равно мощнее, документированее и стабильнее, и
  поэтому может оказаться предпочтительнее во многих (\emph{очень}
  нетривиальных) случаях.
\end{itemize}

\begin{itemize}
\item
  Скаловские парсер-комбинаторы работают медленно. Очень медленно.
  Неприлично медленно. Маттиас проводил сравнение производительности
  парсеров для Jackson и JSON, написанных с помощью Parboiled,
  Parboiled2 и Scala Parser Combinators. С неутешительными результатами
  для последних можно ознакомиться дальше по тексту.
\item
  В отличие от
  \href{http://martinfowler.com/bliki/LanguageWorkbench.html}{Language
  Workbenches}, Parboiled --- маленькая и простая в использовании
  библиотека. Вам не нужно скачивать плохо документированного
  тормозящего монстра и тратить драгоценные часы жизни на изматывающий
  поиск нужных менюшек и кнопочек всего-навсего для описания небольшого
  DSL. С другой стороны, вы не получите готовый текстовый редактор с
  подсветкой вашего DSL из коробки, вместо этого вам придется
  самостоятельно написать плагин для Vim, Emacs или вашей IDE, но это не
  делает Parboiled менее достойной альтернативой для разработки
  небольших предметно-ориентированных языков.
\end{itemize}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Parboiled успешно зарекомендовал себя во
  \href{https://github.com/sirthias/parboiled/wiki/Projects-using-parboiled}{многих
  проектах}, в том числе и в кровавом энтерпрайзе.
\end{itemize}

\subsection{Новое в версии
два}\label{ux43dux43eux432ux43eux435-ux432-ux432ux435ux440ux441ux438ux438-ux434ux432ux430}

Этот раздел, в основном, будет полезен и понятен тем, кто уже работал с
первой версией библиотеки. Новичкам, скорее всего, стоит вернуться к
этому списку после прочтения всего цикла статей.

Прежде всего, Parboiled2 успешно устраняет ряд детских болезней первой
версии:

\begin{itemize}
\item
  Появилась возможность использовать правила более вместительные, чем
  \texttt{Rule7}. Для этого была использована библиотека
  \href{https://github.com/milessabin/shapeless}{shapeless} с ее
  знаменитыми \texttt{HListами}: теперь одно правило может оперировать
  большим количеством значений на стеке. Это также означает, что в
  Parboiled2 появилась дополнительная зависимость, которой не было в PB1
  --- сама библиотека shapeless.
\item
  Добавлены недостающие конструкции. Так, в Parboiled1 нельзя было
  указать динамическое количество повторений для правила \texttt{nTimes}
  и приходилось использовать более «мягкое» правило \texttt{oneOrMore},
  что не давало нужной точности описания грамматики.
\item
  Добавлены встроенные примитивные терминалы. Появился новый класс
  \texttt{CharPredicate}, который содержит такие поля, как
  \texttt{AlphaNumeric}, \texttt{Hex}, \texttt{Printable},
  \texttt{Visible} и другие.
\item
  Добавлена возможность расширения и сужения предиката. Потребность
  исключить несколько символов из правила возникала и раньше, но только
  теперь это можно с легкостью взять и сделать, а не создавать белый
  список символов.
\end{itemize}

Кроме того:

\begin{itemize}
\item
  Parboiled2 использует макросы, что позволяет генерировать грамматику
  на этапе компиляции, а не во время выполнения, как это было в
  Parboiled1. Это многократно увеличивает производительность вашего
  парсера, так же как увеличивает количество проверок. В связи с этим
  блок \texttt{rule} стал обязательным, хотя Parboiled1 позволял в
  некоторых случаях обходиться без него. Это нововведение вы заметите в
  первую очередь, когда будете делать миграцию старого кода.
\item
  Улучшена система отчета об ошибках.
\item
  Появилась поддержка \href{http://www.scala-js.org/}{scala.js}.
  Демо-проект можно посмотреть
  \href{https://github.com/alexander-myltsev/parboiled2-scalajs-samples}{здесь}.
\end{itemize}

\section{Сравнения
производительности}\label{ux441ux440ux430ux432ux43dux435ux43dux438ux44f-ux43fux440ux43eux438ux437ux432ux43eux434ux438ux442ux435ux43bux44cux43dux43eux441ux442ux438}

Parboiled1 известен своей медлительностью (во всяком случае, по
отношению к парсерам, генерируемым ANTLR), вызванной тем, что все
действия по сопоставлению правил выполнялись в рантайме и компилятор не
мог производить над таким парсером каких-либо существенных оптимизаций.
В Parboiled2 во главу угла поставили производительность и многие вещи
были переделаны на макросах, благодаря чему компилятор получил свободу
действий при оптимизации, а пользователь --- долгожданную
производительность. Ниже мы продемонстрируем, каких неплохих результатов
добились разработчики.

\subsection{Parboiled против парсеров JSON, написанных прямыми
руками}\label{parboiled-ux43fux440ux43eux442ux438ux432-ux43fux430ux440ux441ux435ux440ux43eux432-json-ux43dux430ux43fux438ux441ux430ux43dux43dux44bux445-ux43fux440ux44fux43cux44bux43cux438-ux440ux443ux43aux430ux43cux438}

Parboiled --- это обобщённый инструмент для создания парсеров, а как
известно, специализированный инструмент всегда оказывается лучше
обобщённого в решении своей специализированной задачи. В мире Java
существует небольшое количество парсеров JSON, написанных вручную
древними эльфийскими мастерами, и Александр Мыльцев (один из
разработчиков Parboiled2) проверил, насколько сильно Parboiled
проигрывает в производительности этим артефактам.
\href{http://myltsev.name/ScalaDays2014/\#/}{Результаты} оказались
достаточно оптимистичными, особенно в случае с Parboiled2.

\begin{verbatim}
  Тест-кейс                           │ Время, мс │
──────────────────────────────────────┼───────────┼─────────────────────────────────
  Parboiled1JsonParser                │     85.64 │ ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
  Parboiled2JsonParser                │     13.17 │ ▇▇▇▇
  Json4SNative                        │      8.06 │ ██▍
  Argonaut                            │      7.01 │ ▇▇
  Json4SJackson                       │      4.09 │ ▇
\end{verbatim}

\subsection{Parboiled против регулярных
выражений}\label{parboiled-ux43fux440ux43eux442ux438ux432-ux440ux435ux433ux443ux43bux44fux440ux43dux44bux445-ux432ux44bux440ux430ux436ux435ux43dux438ux439}

Благодаря использованию статических оптимизаций, Parboiled2 способен
работать значительно быстрее регулярных выражений (как минимум тех, что
идут в комплекте с библиотекой классов Java). Вот немного подтверждающих
данных из
\href{https://groups.google.com/forum/\#!msg/parboiled-user/XATcJRLTXjA/XSmf3n6gZSwJ}{списка
рассылки}:

\begin{verbatim}
  Тест-кейс                           │ Время, мс │
──────────────────────────────────────┼───────────┼───────────────────────────────────
  Parboiled2 (warmup)                 │   1621.21 │ ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
  Parboiled2                          │    409.16 │ ▇▇▇▇▇▇▇▇
  Parboiled2 w/ better types (warmup) │    488.92 │ ▇▇▇▇▇▇▇▇▇▇
  Parboiled2 w/ better types          │    134.68 │ ▇▇▇
  Regex (warmup)                      │    621.95 │ ▇▇▇▇▇▇▇▇▇▇▇▇
  Regex                               │    620.38 │ ▇▇▇▇▇▇▇▇▇▇▇▇
\end{verbatim}

\subsection{Parboiled против Scala Parser
Combinators}\label{parboiled-ux43fux440ux43eux442ux438ux432-scala-parser-combinators}

В списке рассылки можно найти и
\href{https://groups.google.com/forum/\#!topic/parboiled-user/bGtdGvllGgU}{другой
тест производительности}, который неплохо согласуется с первым (про
JSON) и содержит данные для сравнения со Scala Parser Combinators. Всё
очень и очень печально.

\begin{verbatim}
  Тест-кейс                           │ Время, мс │
──────────────────────────────────────┼───────────┼─────────────────────────────────
  Parboiled1JsonParser                |     73.81 | ▇
  Parboiled2JsonParser                |     10.49 | ▎
  ParserCombinators                   |   2385.78 | ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
\end{verbatim}

\section{Чего Parboiled не
может}\label{ux447ux435ux433ux43e-parboiled-ux43dux435-ux43cux43eux436ux435ux442}

Большинство статей про комбинаторы парсеров начинается с изматывающих
объяснений того, что такое PEG, с чем его есть и почему его надо
бояться. Для того чтобы парсить конфиги, досконально разбираться в этом
не обязательно, но знать об ограничениях данного типа грамматик всё
равно стоит. Итак, Parboiled принципиально не умеет:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Разбирать леворекурсивные грамматики. Это не под силу всем нисходящим
  парсерам (top-down parsers), к коим относятся и PEG. Однако,
  леворекурсивную грамматику можно
  \href{http://neerc.ifmo.ru/wiki/index.php?title=Устранение_левой_рекурсии}{адаптировать}.
\end{itemize}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Разбирать грамматики на отступах (indentation-based grammars),
  например Python или YAML. Не получается это сделать из-за того, что
  сгенерированный парсер является однопроходным, без отдельного лексера.
  Разбор отступов же выполняется на этапе лексического анализа. У этой
  проблемы есть простое решение: напишите препроцессор, который
  расставит виртуальные маркеры до (\texttt{INDENT}) и после
  (\texttt{DEDENT}) выхода в отступ. В Parboiled1 имеются для этого
  \href{https://github.com/sirthias/parboiled/wiki/Indentation-Based-Grammars}{стандарные
  инструменты}, но для Parboiled2 подобную процедуру пока что придётся
  выполнять самостоятельно.
\end{itemize}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Использовать потоковый ввод (streaming input). PEG используют поиск с
  возвратом, он же
  \href{https://en.wikipedia.org/wiki/Backtracking}{бэктрекинг}.
  Теоретически, этот недостаток можно устранить при помощи буферизации
  потока, но ничто не мешает написать такую грамматику, в которой
  происходит возврат к самому началу. Поэтому, чтобы эта идея заработала
  на практике, необходимо научиться определять по грамматике границы
  чанков, между которыми возврат невозможен. Матиас весьма
  \href{https://groups.google.com/d/msg/parboiled-user/b7PH49fiFco/gGt46xe3Ae4J}{заинтересован}
  в разработке этой фичи, так что возможно ее появление в следующих
  релизах.
\end{itemize}

В следующей части я расскажу о том, как в Parboiled описывается
пользовательская грамматика, а ещё мы напишем простой распознаватель для
древовидного формата конфигурационных файлов.

\section{Подготовительные
работы}\label{ux43fux43eux434ux433ux43eux442ux43eux432ux438ux442ux435ux43bux44cux43dux44bux435-ux440ux430ux431ux43eux442ux44b}

Перед началом работы с библиотекой добавим её в classpath. В Maven,
например, это делается так:

\begin{verbatim}
<dependency>
    <groupId>org.parboiled</groupId>
    <artifactId>parboiled_2.11</artifactId>
    <version>2.1.0</version>
</dependency>
\end{verbatim}

Я использую Scala 2.11, однако существуют артефакты и для 2.10.

\section{Язык описания правил (Rule
DSL)}\label{ux44fux437ux44bux43a-ux43eux43fux438ux441ux430ux43dux438ux44f-ux43fux440ux430ux432ux438ux43b-rule-dsl}

Вся функциональность Parboiled реализуется поверх синтаксиса языка Scala
при помощи специализированного DSL. Поэтому описание парсера на самом
деле есть ни что иное, как объявление класса, производного от
\texttt{org.parboiled.Parser}. В качестве примера напишем парсер,
который ничего не делает, что не мешает ему существовать и радоваться
жизни:

\begin{verbatim}
import org.parboiled2._

class MyParser(val input: ParserInput) extends Parser {
  // Здесь описана ваша грамматика
}
\end{verbatim}

Конструкции DSL и ряд полезных классов добавляются в зону видимости
всего одной директивой импорта. Хочу отметить, что наличие параметра
\texttt{input} в конструкторе является обязательным: это означает, что
для каждого нового набора входных данных нужно создавать новый
объект-парсер. Вначале меня это очень сильно пугало, но я перестал
бояться, когда увидел, как быстро оно работает.

\subsection{Правила для отдельных
символов}\label{ux43fux440ux430ux432ux438ux43bux430-ux434ux43bux44f-ux43eux442ux434ux435ux43bux44cux43dux44bux445-ux441ux438ux43cux432ux43eux43bux43eux432}

Итак, когда никчёмный парсер у нас уже имеется, нужно добавить в него
несколько правил, в соответствии с которыми он и будет обрабатывать
данные. Если вы работали с Parboiled1, этот раздел можно просто
пролистать, так как мои объяснения могут показаться вам излишне
подробными.

Начнем с терминалов. Этот термин будет использоваться в дальнейшем,
поэтому попробуем дать ему здесь определение (не совсем, впрочем,
строгое):

\begin{quote}
Терминал --- это простейшее атомарное правило, не требующие
дополнительных определений
\end{quote}

Давайте опишем два простейших правила: первое должно распознать
некоторый наперёд известный символ, второе --- строку:

\begin{verbatim}
def MyCharRule   = rule { ch('a') }
def MyStringRule = rule { str("string") }
\end{verbatim}

Каждый раз обозначать свои намерения подобным образом весьма
утомительно. И здесь нам на помощь приходит механизм неявных
преобразований (implicit conversions), который позволяет сделать правила
короче:

\begin{verbatim}
def MyCharRule   = rule { 'a' }
def MyStringRule = rule { "string" }
\end{verbatim}

Строки сопоставляются с точным учётом регистра символов. Тем не менее,
существует множество языков, не чувствительных к регистру (например
SQL). Для них существует правило \texttt{ignoreCase}, сопоставляющее
входную строку независимо от ее регистра. Передаваемая в него строка
обязательно должна быть в нижем регистре:

\begin{verbatim}
def StringWithCaseIgnored = rule { ignoreCase("string") }
\end{verbatim}

Подробнее о правилах (или «продукциях», если вам так нравится больше)
будет рассказано в следующей статье. Все приведенные выше (и ниже)
правила имеют тип \texttt{Rule0}. Правила бывают разных типов, но сейчас
нам необходимо знать лишь то, что \texttt{Rule0} обозначает, что правило
сопоставляет с собой входную строку и говорит, совпало или нет. Мы не
указали тип потому, что механизм вывода типов языка пока легко
справляется и сам. Однако, ничто не мешает нам указать тип явно:

\begin{verbatim}
def StringWithCaseIgnored: Rule0 = rule { ignoreCase("string") }
\end{verbatim}

В Parboiled существуют особенные терминалы (они же синтаксические
предикаты):

\begin{itemize}
\item
  \texttt{ANY} --- любой символ, кроме \texttt{EOI}.
\item
  \texttt{EOI} (End of Input) --- виртуальный символ-маркер конца ввода,
  который вы обязательно захотите добавить в главное правило своего
  парсера. Определяется \texttt{EOI} так:

\begin{verbatim}
val EOI = '\uFFFF'
\end{verbatim}
\end{itemize}

Несмотря на то, что символ U+FFFF зарезервирован для внутреннего
использования стандартом Юникода, на практике он может запросто
встретиться в пользовательском вводе и изменить поведение парсера.
Поэтому будьте внимательны с текстом, который попадает на вход.

Кроме того, если вы не добавите \texttt{EOI} в конце главного правила и
при сопоставлении возникнет ошибка, то о ней вы не узнаете, так как
парсер будет считать, что входные данные ещё не закончились и будет
ожидать поступления новых данных. Поэтому, что бы вы не подали на вход,
на выходе вас ожидает бессмысленный Success.

Из правил \texttt{chr} и \texttt{str} вряд ли можно составить полезный
парсер, поэтому первым шагом к осмысленности станет возможность
определять \emph{диапазон} допустимых симовлов. В Parboiled2 это
делается очень легко:

\begin{verbatim}
def Digit      = rule { '0' - '9' }
def AlphaLower = rule { 'a' - 'z' }
\end{verbatim}

Оба эти правила сопоставят за раз максимум один символ из диапазона (или
не сопоставят ни одного). Хотя написать конкретно эти два правила в PB2
очень просто, делать это нет необходимости: они уже определены в объекте
\texttt{CharPredicate}. Parboiled1, напротив, заставлял вручную
создавать эти правила, практически каждый раз, когда вы пишете очередной
парсер. Поэтому я носил свою библиотечку примитивов из проекта в проект
(уверен, что не я один так делал). Теперь моя библиотечка заметно
подыстощилась благодаря появлению \texttt{CharPredicate}. В него входят,
например, следующие правила (думаю, что из названий будет понятно, каким
категориям символов они соответствуют):

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{CharPredicate.All} (работает почти так же, как \texttt{ANY},
  но показывает худшую производительность на больших диапазонах
  символов);
\item
  \texttt{CharPredicate.Digit};
\item
  \texttt{CharPredicate.Digit19};
\item
  \texttt{CharPredicate.HexDigit} и много других правил.
\end{itemize}

Если вас не устаивают имеющиеся правила, вы всегда сможете определить
свой собственный символьный предикат, для этого необходимо использовать
метод \texttt{from}:

\begin{verbatim}
CharPredicate from (_.isSpaceChar)
\end{verbatim}

Кроме того, для символьных предикатов определены операторы
\texttt{except} (\texttt{-\/-}) и \texttt{union} (\texttt{++}), которых
не было в PB1. Лично я от этого отсутствия очень страдал: приходилось
замыкать правило «с другой стороны», перечисляя полностью черный или
белый список символов в зависимости от ситуации. Правило \texttt{-\/-}
можно так же назвать разностью, так как роль у него накая же, что и у
\href{https://ru.wikipedia.org/wiki/Разность_множеств}{разности двух
множеств}.

\begin{verbatim}
// Сопоставит любой печатный символ, если это не кавычка.
def AllButQuotes = rule { CharPredicate.Visible -- "\"" -- "'" }

// Неплохо подойдет для определения идентификатора. Обратите внимание, как
// AlphaNum объединяется с нижним подчеркиванием.
def ValidIdentifier = rule {
  CharPredicate.Alpha ~ zeroOrMore(CharPredicate.AlphaNum ++ "_") }
\end{verbatim}

Полезно будет знать ещё о двух правилах: \texttt{anyOf} и
\texttt{noneOf}. Они очень похожи на \texttt{except} и \texttt{union},
но работают на всём пространстве символов \texttt{ANY}. И самое главное:
в этом пространстве они работают быстрее. Эти функции могут принимать на
вход строку, состоящую из перечислений символов. Например:

\begin{verbatim}
// Определит, является ли символ одной из арифметических операций.
def ArithmeticOperation = rule { anyOf("+-*/^") }

// Сопоставит всё, кроме перечисленных пробельных символов и EOI.
def WhiteSpaceChar = rule { noneOf(" \t\n") }
\end{verbatim}

Иногда возникает вопрос, что же выбрать: \texttt{anyOf}/\texttt{noneOf}
или \texttt{CharPredicate}? Заранее предопределенный символьный предикат
будет работать быстрее для 7-битных символов ASCII. «Заранее
предопределенный» написано не просто так, и в разделе «Best Practices»
части 4 будет рассказано, почему. Однако для очень больших символьных
диапазонов \texttt{CharPredicate} ведёт себя откровенно плохо, и тогда
на помощь должны прийти \texttt{anyOf} и \texttt{noneOf}.

\subsection{Цепочки
правил}\label{ux446ux435ux43fux43eux447ux43aux438-ux43fux440ux430ux432ux438ux43b}

\subsubsection{N.times}\label{n.times}

Сопоставлять единичные символы не интересно, поэтому перейдем к более
сложным правилам. Начнём с \texttt{times}, которое позволяет сопоставить
одно правило несколько раз подряд. Количество повторений должно быть
точным и заранее известным.

\begin{verbatim}
def BartLearningParboiled = rule {
  100 times "I will never write a parser again. "
}
\end{verbatim}

Некоторые грамматики требуют жесткого диапазона числа повторений,
например
\href{http://www.chukfamily.ru/Kornei/Prosa/Ot2do5/Ot2do5.htm}{от двух
до пяти}. В новом Parboiled это можно легко устроить:

\begin{verbatim}
def FutureOfCxx = rule { 'C' ~ (2 to 5).times('+') }
\end{verbatim}

А в старом --- существует правило \texttt{nTimes}, которое, требует
указания точного числа повторений. В случае, если точное количество
повторений заранее не известно, вам помогут следующая пара правил.

\subsubsection{zeroOrMore}\label{zeroormore}

Как вы уже наверное догадались из названия, zeroOrMore сопоставляет
последновательность из нуля и более вхождений указанного правила.
Внимательный читатель уже заметил это правило в примерах и оно ему,
скорее всего, показалось хорошо знакомым: в регулярных выражениях точно
такая же операция обозначается звёздочкой, а любители академической
терминологии, кроме того, знают, что она называется
\href{https://ru.wikipedia.org/wiki/\%D0\%97\%D0\%B2\%D0\%B5\%D0\%B7\%D0\%B4\%D0\%B0_\%D0\%9A\%D0\%BB\%D0\%B8\%D0\%BD\%D0\%B8}{звездой
Клини}. В любом случае, использовать это правило очень просто:

\begin{verbatim}
def Whitespace = rule { anyOf(" \n\t") }
def OptWs      = rule { zeroOrMore(Whitespace) }
\end{verbatim}

\subsubsection{oneOrMore}\label{oneormore}

Правило, похожее на предыдущее. Оно делает почти то же самое, что и
\texttt{zeroOrMore}, но требует, чтобы по крайней мере одно повторение
присутствовало во входных данных. Идентично плюсу Клини для регулярных
грамматик.

\begin{verbatim}
def UnsignedInteger = rule { oneOrMore(CharPredicate.Digit) }
\end{verbatim}

\subsubsection{Разделитель цепочек:
separatedBy}\label{ux440ux430ux437ux434ux435ux43bux438ux442ux435ux43bux44c-ux446ux435ux43fux43eux447ux435ux43a-separatedby}

Часто приходится иметь дело со случаем, когда множество элементов
записывается подряд через некоторый разделитель: это и CSV, и
определения списков или массивов, и перечисления аргументов функции
через запятую, и многое другое. В Parboiled2 парсинг таких
последовательностей делается легко и непринужденно:

\begin{verbatim}
def CommaSeparatedNumbers = rule { oneOrMore(UnsignedInteger).separatedBy(",") }
\end{verbatim}

Однако, первая версия использует для этого менее элегантный синтаксис:

\begin{verbatim}
def CommaSeparatedNumbers = rule { oneOrMore(UnsignedInteger, separator = ",") }
\end{verbatim}

\subsubsection{Оператор последовательности
(\textasciitilde{})}\label{ux43eux43fux435ux440ux430ux442ux43eux440-ux43fux43eux441ux43bux435ux434ux43eux432ux430ux442ux435ux43bux44cux43dux43eux441ux442ux438}

Для того чтобы указать последовательность правил используется оператор
\texttt{\textasciitilde{}}. В регулярных выражениях нет необходимости в
подобном операторе, там этот факт записывается непосредственным образом,
так же, как и в некоторых вариантах BNF. Для примера напишем (предельно
упрощенное) правило которое сопоставляет дату определенного формата:

\begin{verbatim}
import CharPredicate.Digit

// Дата должна иметь следующий формат: "yyyy-mm-dd"
def SimplifiedRuleForDate = rule { Year ~ "-" ~ Month ~ "-" ~ Day }

def Year  = rule { Digit ~ Digit ~ Digit ~ Digit }
def Month = rule { Digit ~ Digit }
def Day   = rule { Digit ~ Digit }
\end{verbatim}

Как видите, правило максимально упрощено, и я прекрасно отдаю отчет
тому, что у нас может быть 99 дней и 99 месяцев. Не все проверки имеет
смысл оставлять на уровне парсера: мы всё равно передадим сопоставленную
строку на вход какому-нибудь классу для работы с датой и временем,
который догадается выполнить валидацию, и вернет результат, обернутый в
Option. А вот грамматику этим мы заметно упростим. Попытка заставить
парсер выполнить все возможные и невозможные проверки часто приводит к
\href{http://www.ex-parrot.com/~pdw/Mail-RFC822-Address.html}{подобным
результатам}.

\subsubsection{«Необязательное» правило
(optional)}\label{ux43dux435ux43eux431ux44fux437ux430ux442ux435ux43bux44cux43dux43eux435-ux43fux440ux430ux432ux438ux43bux43e-optional}

Если бы существовало правило \texttt{zeroOrOne}, то это и был бы
\texttt{optional}: либо есть одно вхождение, либо вхождений нет совсем.
Давайте разберем следующий пример: в разных семейства операционных
систем маркер конца строки кодируется по-разному. Например, в
Unix-подобных операционных системах нужен только символ
\texttt{\textbackslash{}n}, тогда как в Windows исторически используется
последовательность из двух символов: \texttt{\textbackslash{}r} и
\texttt{\textbackslash{}n}. И если мы хотим обрабатывать текст,
созданный в любой из этих систем, то можно использовать следующее
правило для конца строки:

\begin{verbatim}
def Newline = rule { optional('\r') ~ '\n' }
\end{verbatim}

\subsubsection{Упорядоченный выбор
(\textbar{})}\label{ux443ux43fux43eux440ux44fux434ux43eux447ux435ux43dux43dux44bux439-ux432ux44bux431ux43eux440}

Аналог оператора \texttt{\textbar{}} в регулярных выражениях, неспроста
называемый \emph{упорядоченным} выбором (ordered choice). Предположим,
что нам нужно распознать число, у которого может быть знак, а может, и
не может. Знак, если он есть, может быть двух типов: положительный и
отрицательный, разберемся сначала с ним:

\begin{verbatim}
def Signum = rule { '+' | '-' }
\end{verbatim}

Знак может вовсе отсутствовать в записи положительного числа:

\begin{verbatim}
def MaybeSign = rule { optional(Signum) }
\end{verbatim}

Тогда само число в любом случае представится в виде последовательности
из возможного вхождения знака числа и его модуля --- числа без знака:

\begin{verbatim}
def Integer = rule { MaybeSign ~ UnsignedInteger }
\end{verbatim}

Порядок перечисления вариантов в правиле \texttt{Signum} имеет значение:
выбирается самый первый из подошедших вариантов, что исключает
возможность появления неоднозначности у грамматики. И да, так работают
все без исключения PEG-парсеры. Так что, если вам нужно разобрать
выражение на языке C, начинать перечисление нужно с самых длинных
операций, чтобы они сопоставились первыми, как и предписывает стандарт.
Упрощённо правило может выглядеть, например, так:

\begin{verbatim}
def Operator = rule {
  "+=" | "-=" | "*=" | "/=" | "%=" | "&=" | "^=" | "|=" | "<<=" | ">>=" |
  "<<" | ">>" | "<=" | ">=" | "==" | "!=" |
  "||" | "&&" | "->" | "++" | "--" |
  "<"  | ">"  | "+"  | "-"  | "&"  | "|" | "." |
  "*"  | "/"  | "!"  | "~"  | "^"  | "=" | ","
}
\end{verbatim}

Порядок перечисления может быть самым различным, но нужно обеспечить,
чтобы в нём \texttt{+} всегда шёл после \texttt{+=} и \texttt{++}, а
\texttt{\textless{}} --- после \texttt{\textless{}=} и
\texttt{\textless{}\textless{}} (а \texttt{\textless{}\textless{}}, в
свою очередь, после \texttt{\textless{}\textless{}=}). В противном
случае может случиться, что составной оператор присваивания
\texttt{\textless{}\textless{}=} распарсится в последовательность
{[}\texttt{\textless{}=}, \texttt{=}{]}, а то и вовсе
{[}\texttt{\textless{}}, \texttt{\textless{}}, \texttt{=}{]}.

Если правило выбора становится избыточно сложным и нам не хочется
полагаться на порядок его элементов, стоит сгруппировать их по общим
префиксам (факторизовать парсер):

\begin{verbatim}
def Operators = rule {
  ("+" ~ optional("=" | "+")) |
  ("<" ~ optional("=" | ("<" ~ optional("=")))) | ...
}
\end{verbatim}

Заметим, однако, что ни один из наших примеров не сможет автоматически
учитывать приоритеты операторов, для этого придётся прибегнуть к более
изощрёным правилам.

\subsubsection{Немного
сахара}\label{ux43dux435ux43cux43dux43eux433ux43e-ux441ux430ux445ux430ux440ux430}

Для \texttt{optional}, \texttt{oneOrMore} и \texttt{zeroOrMore}
существует синтаксический сахар, позволяющий сделать определения ещё
короче: \texttt{.?}, \texttt{.+} и \texttt{.*}. Пожалуйста, используйте
их мудро: при злоупотреблении ими, ваши правила будут читаться немногим
лучше, чем регулярки. С помощью этих «ярлыков» мы можем сделать описание
наших правил менее многословным:

\begin{verbatim}
import CharPredicate.Digit
def SignedInteger   = rule { (+ | -).? ~ Digit.+ }

def Newline = rule { '\r'.? ~ '\n' }

def OptWs = rule { WhitespaceChar.* }
\end{verbatim}

\subsubsection{Запуск
парсера}\label{ux437ux430ux43fux443ux441ux43a-ux43fux430ux440ux441ux435ux440ux430}

Для того, чтобы заставить написанный парсер сделать хоть что-то
полезное, нужно вызвать метод \texttt{run} его главного (корневого)
правила. Если вы пишете модульный-тест для парсера, то возможно, имеет
смысл вызывать этот метод и для других правил. Скобочки после метода при
этом обязательны.

Давайте заставим работать наш бесполезный парсер, умеющий сопоставлять
только одну строковую константу. Итак наш парсер определён следующим
образом (не забываем про \texttt{EOI}):

\begin{verbatim}
import org.parboiled2._

class MyParser(val input: ParserInput) extends Parser {
  def MyStringRule: Rule0 = rule { ignoreCase("match") ~ EOI }
}
\end{verbatim}

Теперь где-нибудь в другом месте создадим несколько экземпляров парсеров
и подадим им на вход разные данные:

\begin{verbatim}
val p1 = new MyParser("match")
val p2 = new MyParser("Match")
val p3 = new MyParser("much")

// по-умолчанию возвращают scala.util.Try
p1.MyStringRule.run()      // Success
p2.MyStringRule.run()      // Success
p3.MyStringRule.run()      // Failure
\end{verbatim}

Прогон правил в Parboiled2 намного проще, чем в Parboiled1, для которого
существует целый зоопарк раннеров (parser runners), которые приходится
дополнительно вызывать. За более подробной информацией прошу в раздел
«Отчеты об ошибках» части 4.

\subsubsection{Вложенные структуры
данных}\label{ux432ux43bux43eux436ux435ux43dux43dux44bux435-ux441ux442ux440ux443ux43aux442ux443ux440ux44b-ux434ux430ux43dux43dux44bux445}

Разбор рекурсивных структур --- это то, что может Parboiled и не могут
регулярные выражения. В Parboiled это получается естественно и
непринужденно, что мы и продемонстрируем на последующих примерах.
Единственное дополнительное усилие, которое от вас требуется --- явно
объявить тип правил, участвующих в рекурсии.

Разбор рекурсивных структур обычно иллюстрируют на примере калькулятора
арифметических выражений. По моему мнению, пример совершенно не
нагляден. Поэтому мы рассмотрим вымышленный формат конфигурационных
файлов, состоящий из именованных блоков, которые содержат пары
«ключ---значение».

\section{Формат BKV
(Block-Key-Value)}\label{ux444ux43eux440ux43cux430ux442-bkv-block-key-value}

В качестве примера будет использоваться формат «BKV», который был
придуман специально для этого туториала. Он вдохновлялся форматом
\href{https://github.com/typesafehub/config/blob/master/HOCON.md}{HOCON}
и, собственно, является его подмножеством. BKV состоит из пар
ключ---значение и блоков, внутри которых могут размещаться пары.
Выглядит это примерно так:

\begin{verbatim}
server.name = "webserver"
server {
  port    = "8080"
  address = "192.168.88.88"

  settings {
    greeting_message = "Hello!\n It's me!"
  }
}
\end{verbatim}

Как видите, формат прост и незатейлив, хотя строки с экранированием
(escaping) могут напугать тех, кто никогда не писал парсеры.
Экранирование очень часто встречается при синтаксическом разборе,
поэтому мы обязательно и в подробностях его рассмотрим.

\subsection{Экранированные
строки}\label{ux44dux43aux440ux430ux43dux438ux440ux43eux432ux430ux43dux43dux44bux435-ux441ux442ux440ux43eux43aux438}

Для того, чтобы при синтаксическом разборе не иметь проблем с
пробельными и непечатными символами в большинстве грамматик строки
заключаются в двойные или одинарные кавычки (или их некое подобие,
например, могут использоваться открывающие и закрывающие угловые
скобки). Непечатные символы и кавычки --- экранируются.

Для того, чтобы написать распознаватель экранированных строк, необходимо
определиться со следующими элементами синтаксиса:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Символы, открывающие и закрывающиие строку (в нашем случае это один и
  тот же символ --- двойная кавычка).
\item
  Символ экранирования (в нашем случае это символ обратного слеша).
\item
  Набор символов-мнемоник для обозначения непечатных символов (мы будем
  поддерживать, как минимум,
  \texttt{\textquotesingle{}\textbackslash{}n\textquotesingle{}},
  \texttt{\textquotesingle{}\textbackslash{}t\textquotesingle{}} и
  \texttt{\textquotesingle{}\textbackslash{}v\textquotesingle{}}).
\end{itemize}

Сначала попробуем описать правило для квотированной строки без
экранирования:

\begin{verbatim}
def OverlySimplifiedQuotedString = rule {
  '"' ~ zeroOrMore(AllowedChar) ~ '"'
}
\end{verbatim}

Поскольку пустые строки тоже возможны, между кавычками мы используем
правило \texttt{zeroOrMore}. Очевидно, что двойная кавычка в перечень
допустимых символов не входит. Что же тогда разрешено? Всё, что не
запрщено. Поэтому для нашего случая список разрешенных символов выглядит
так:

\begin{verbatim}
def AllowedChar = rule { noneOf("\"") }
\end{verbatim}

Без двойной кавычки жить можно, но сложно. Но что будет, если мы добавим
кавычку внутрь строки? Встретив её, парсер подумает, что строка
закончилась, и взорвётся сообщением об ошибке на следующем же символе.

Символ экранирования предупреждает парсер о том, что следущий символ
особенный. Алгоритм выглядит таким образом: парсер ожидает один из
разрешенных символов или экранированную последовательность, а
экранированная последовательность состоит из символа экранирования и
следующего за ним оператора выбора одного из символов:

\begin{verbatim}
def AllowedChar = rule {
  noneOf("\"\\") | EscapeSequence
}

// Поддерживаются последовательности: \", \\, \n, \a, \f, \v.
def EscapeSequence = rule {
  '\' ~ anyOf("\"\\nafv")
}
\end{verbatim}

Разобравшись, как это работает, можно переходить к написанию финального
варианта правил для экранирования. Для этого предлагаю создать
выделенный трейт:

\begin{verbatim}
import org.parboiled2._

object QuotedStringSupport {
  val CharsToBeEscaped = "abfnrtv\\\""
  val Backslash = '\\'
  val AllowedChars = CharPredicate.Printable -- Backslash -- '"'
}

trait QuotedStringSupport { this: Parser =>
  import QuotedStringSupport._

  def QuotedString: Rule0 = rule {
    '"' ~ QuotedStringContent  ~ '"'
  }

  def QuotedStringContent: Rule0 = rule {
    oneOrMore(AllowedChars | DoubleQuotedStringEscapeSequence)
  }

  def DoubleQuotedStringEscapeSequence = rule {
    '\\' ~ anyOf(CharsToBeEscaped)
  }
}
\end{verbatim}

Теперь, когда мы расквитались со строками и выделили соответствующую
функциональность в отдельный трейт, перейдем к самому формату.

\subsection{Вспомогательные
терминалы}\label{ux432ux441ux43fux43eux43cux43eux433ux430ux442ux435ux43bux44cux43dux44bux435-ux442ux435ux440ux43cux438ux43dux430ux43bux44b}

В написании парсеров существует два подхода: «от общего к частному» и
«от частного к общему». Обычно грамматики описываются согласно первому,
но это всего-лишь туториал, поэтому начнем с деталей помельче, а затем
обобщим.

Начем описание со вспомогательных элементов, а именно, с пробелов. В
нашем случае пробелами будут являться символы: `', `\n' и `\t'. Конечно
же, пробельных символов в природе существует куда больше, но в примере
мы ограничимся тремя. Разобраться с пробелами можно разными способами:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  перечислить символы через оператор упорядоченного выбора;
\item
  объявить свой \texttt{CharPredicate}, содержащий эти три символа;
\item
  использовать \texttt{anyOf}.
\end{itemize}

Мы воспользуемся последним. При этом учтём, что в некоторых местах
пробелов может быть несколько, в других --- не быть вовсе, а кое-где
пробелы должны быть обязательно (но нашему формату обязательные пробелы
не требуются):

\begin{verbatim}
val WhitespaceChars = "\n\t "
def WhiteSpace = rule { anyOf(WhitespaceChars) }
def OptWs      = rule { zeroOrMore(WhiteSpace) }
\end{verbatim}

Правило, описывающее перевод строки мы объявляли ранее:

\begin{verbatim}
def Newline = rule { optional('\r') ~ '\n' }
\end{verbatim}

Ключ и имя блока представляют собой идентификатор, похожий на тот, что
вы можете встретить в различных языках программирования. Идентификатор
должен начинаться либо с буквы английского алфавита (регистр не имеет
значения), либо с символа нижнего подчеркивания. В середине может
содержать цифры а так же буквы английского алфавита (строчные и
заглавные). Вхождение точки, в середине идентификатора тоже допустимо.
Перед тем как объявлять ключ, объявим правило, описывающее
идентификатор. (Аналогичные правила будут применяться для имени блока).
Нам необходимо два символных предиката: для первого и последующих
символов.

\begin{verbatim}
// Первый символ идентификатора
val IdentifierFirstChar = CharPredicate.Alpha ++ '_'

// Для последующих символов
val IdentifierChar      = CharPredicate.AlphaNum ++ '.' ++ '_'
\end{verbatim}

Объявим также символы начала и конца блока:

\begin{verbatim}
val BlockBeginning  = '{'
val BlockEnding     = '}'
\end{verbatim}

Теперь, когда у нас имеются все необходимые вспомогательные терминалы,
займёмся блоками покрупнее.

\subsection{Пары
ключ---значение}\label{ux43fux430ux440ux44b-ux43aux43bux44eux447ux437ux43dux430ux447ux435ux43dux438ux435}

Теперь перейдём к синтаксису пар «ключ--значение». Потребуем, чтобы ключ
представлял собой валидный идентификатор, как описанно выше, а значение
было квотированной строкой, как тоже описано выше. Итак, начнем с
определения идентификатора:

\begin{verbatim}
def Identifier = rule {
  IdentifierFirstChar ~ zeroOrMore(IdentifierChar)
}
\end{verbatim}

Возможно, нам не стоило задавать идентификатор достаточно жестким
правилом, однако в большинстве грамматик с которыми вам, скорее всего
придется столкнуться,используются аналогичные правила. Например,
идентификаторам запрещено начинаться с цифры, ввиду наличия
целочисленных литералов, различные символы могут являться валидными
операторами. Правило описывающее ключ, будет выглядеть так:

\begin{verbatim}
def Key = rule { Identifier }
\end{verbatim}

Для описания значения воспользуемся уже имеющимся правилом (для этого
нам всего-то нужно подмешать написанный нами ранее трейт):

\begin{verbatim}
def Value = rule { DoubleQuotedString }
\end{verbatim}

Теперь опишем правило для всей пары целиком. Тут стоит еще раз напомнить
о том, что Parboiled является PEG, из этого следует, что нам постоянно
нужно помнить о пробелах и сообщать правилу о местах, где они могут
встречаться.

\begin{verbatim}
def KeyValuePair = rule { Key ~ OptWs ~ "=" ~ OptWs ~ Value }
\end{verbatim}

\subsection{Вложенные
блоки}\label{ux432ux43bux43eux436ux435ux43dux43dux44bux435-ux431ux43bux43eux43aux438}

Блок ограничен фигурными скобками и может содержать внутри как пары
«ключ---значение», так и другие блоки. Поэтому для начала нужно стереть
различия между блоками и парами ключ---значение, обозвав и те, и другие
узлами (nodes) синтаксического дерева. Это делается следующим кодом:

\begin{verbatim}
// Тип правила обязателен к указанию, иначе не взлетит!
def Node: Rule0 = rule { KeyValuePair | Block }
\end{verbatim}

Так как и блок, и корневая структура состоят из списка узлов, нам нужно
объявить правило для этого списка:

\begin{verbatim}
def Nodes = rule {
  OptWs ~ zeroOrMore(Node).separatedBy(Newline ~ OptWs) ~ OptWs
}
\end{verbatim}

Опциональные пробелы могут быть и перед списоком нод, и после него, и
между отдельными его элементами, поэтому у нас в правиле получилось так
много вхождений \texttt{MaybeWs}. Теперь определим имя блока --- это всё
тот же идентификатор, что используется и в имени ключа:

\begin{verbatim}
def BlockName = rule { Identifier }
\end{verbatim}

Наконец, всё необходимое для объявления блока целиком у нас есть,
поэтому объявим блок:

\begin{verbatim}
def Block = rule { BlockName ~ "{" ~ Nodes ~ "}" }
\end{verbatim}

Помните мы определяли \texttt{BlockBeginning} и \texttt{BlockEnding}?
Используем их в объявлении:

\begin{verbatim}
def Block = rule { BlockName ~ BlockBeginning ~ Nodes ~ BlockEnding }
\end{verbatim}

Заметьте, что \texttt{Block} ссылается на правило \texttt{Nodes},
которое будет ссылаться на правило Node. Node может ссылаться как на
правило Block, из-за чего возникает цикл. Поэтому нам необходимо явно
указать тип правила, успокоив Parboiled. Так как мы пишем
распознаватель, тип правила всегда будет Rule0 (подробнее о типах правил
будет в следующей статье).

Итак, у нас всё есть, не хватает только точки входа, или корня (root),
который тоже представляет собой ни что иное, как список узлов, для
которого у нас уже есть готовое правило. Используем его, не забыв учесть
возможные пробелы и завершить правило символом \texttt{EOI}:

\begin{verbatim}
def Root: Rule0 = rule { Nodes ~ EOI }
\end{verbatim}

Вот мы и написали распознаватель. Ознакомиться с его полным исходным
кодом вы можете
\href{https://gist.github.com/ppopoff/1bbf022327750f37ebcc}{здесь}.

Так как только лишь сопоставлять значения на практике приходится весьма
редко, а извлекать их из текста --- постоянно, в следующей статье я
расскажу вам захватывающие истории о том, как это делается, а также о
типах правил. В ней же мы и доведем наш распознаватель до состояния
полноценного парсера.

\section{Стек значений (Value
Stack)}\label{ux441ux442ux435ux43a-ux437ux43dux430ux447ux435ux43dux438ux439-value-stack}

Прежде чем извлекать какие-либо данные при помощи правил, следует
немного рассказать про одну из концепций, которая реализована в
Parboiled. Она называется Value Stack и ее можно не совсем корректно
перевести как «стек значений». Представляет он собой, действительно,
стек, который модифицируется \emph{действиями парсера} (parser actions),
в него помещаются и из него извлекаются результаты парсинга правил.
Именно этому стеку мы должны дать подсказку при объявлении рекурсивных
правил. Для того, чтобы элементы были помещены на стек, их необходимо
явно захватить, что отразится на виде ваших правил. Типы правил также
отражают количество захваченных элементов и их тип. Элементы стека могут
иметь разный тип, а типизация стека значений проверяется на этапе
компиляции.

\section{Типы
правил}\label{ux442ux438ux43fux44b-ux43fux440ux430ux432ux438ux43b}

В Parboiled2 существуют следующие типы правил:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{Rule0} --- просто отвечает на вопрос ``Сопоставилось ли?'', не
  изменяя содержимое стека.
\item
  \texttt{Rule1} --- помещает один объект в стек значений.
\item
  \texttt{Rule2} --- помещает два объекта в стек значений.
\item
  \texttt{RuleN} --- помещает N объектов в стек значений, используя
  семантику библиотеки Shapeless. Для работы с Parboiled2 знать
  Shapeless не нужно (хотя и будет полезно).
\item
  \texttt{PopRule} --- извлекает значения со стека, не помещая туда
  новых значений.
\end{itemize}

При желании можно объявить свои псевдонимы для типов, как это было в
Parboiled1. Так, например, в коде Parboiled2 реализуется \texttt{Rule2}:

\begin{verbatim}
type Rule2[+A, +B] = RuleN[A :: B :: HNil]
\end{verbatim}

В Parboiled1 для каждого количества аргументов от 0 до 7 существовал
отдельный тип, что создавало так называемую «проблему \texttt{Rule7}»:
класса \texttt{Rule8} уже нет и положить восемь элементов в стек
значений не получится, даже если очень хочется. Существуют различные
пути для обхода этой проблемы, и про один из них я расскажу в следующей
статье.

\section{Действия парсера (parser
actions)}\label{ux434ux435ux439ux441ux442ux432ux438ux44f-ux43fux430ux440ux441ux435ux440ux430-parser-actions}

Действия парсера стоило бы назвать действиями над стеком, так как они
позволяют извлекать данные из сопоставившихся правил, преобразовывать
их, а при условии высокой степени вашей испорченности --- производить с
ними сайд-эффекты (что может в некоторых случах быть действительно
необходимым, например, если размер и количество извлекаемых данных
заранее не известны). С помощью действий можно формировать абстрактные
синтаксические деревья
(\href{https://en.wikipedia.org/wiki/Abstract_syntax_tree}{AST}), их
можно использовать для вычисления «на месте», как это сделано в
\href{calc}{примере с калькулятором}.

\section{Захватывающие
истории}\label{ux437ux430ux445ux432ux430ux442ux44bux432ux430ux44eux449ux438ux435-ux438ux441ux442ux43eux440ux438ux438}

Чтобы совершить какое-то полезное дейстие над данными, нам надо их
сначала захватить. Для этого существует функция \texttt{capture}: она
сопоставляет данные с правилом и в случае успеха помещает их на стек
значений.

Предположим у нас есть правило типа \texttt{Rule0}, из которого мы хотим
хоть что-то вытащить:

\begin{verbatim}
def User: Rule0 = rule { FirstName ~ Separator ~ LastName }
\end{verbatim}

Нам нужно решить, что именно мы будем захватывать, хоть и очевидно, что
разделитель не представляет никакой художественной ценности:

\begin{verbatim}
def User: Rule2[String, String] = rule {
  capture(FirstName) ~ Separator ~ capture(LastName)
}
\end{verbatim}

С этого момента наше правило уже не \texttt{Rule0}, а \texttt{Rule2},
так как оно захватывает и оправляет в стек значений две строки. Впрочем,
тип можно и не указывать, компилятор все поймет сам.

\subsection{Оператор действия
\textasciitilde{}\textgreater{}}\label{ux43eux43fux435ux440ux430ux442ux43eux440-ux434ux435ux439ux441ux442ux432ux438ux44f}

\ldots{} или оператор, которым вам придется пользоваться чаще всего. В
качестве правого параметра принимает лямбду, на вход которой отправляет
захваченные со стека объекты --- тем самым позволяя лямбде с этими
объектами работать. Потом, при желании, значения можно отправить обратно
в стек, или же создать из них узел для вашего AST --- выберите по своему
вкусу. В любом случае, для того, чтобы действие осуществилось, нужно
предварительно выполнить захват данных на стек при помощи функции
\texttt{capture}. В зависимости от типа возвращаемого значения
используются различные формы оператора
\texttt{\textasciitilde{}\textgreater{}}, что делает использование
данного оператора простым и интуитивным.

\begin{quote}
В Parboiled1 захват выполнялся неявно, что я нахожу весьма неудобным.
\end{quote}

Теперь немного подробнее про лямбду. Ее сигнатура зависит от количества
и типизации захваченных объектов, причем за раз лямбда может захватить
\href{https://github.com/sirthias/parboiled2/issues/85}{не более 22
аргументов}. Типы аргументов лямбды соответствуют типам значений,
снимаемых со стека, а типы возвращаемых значений --- типам значений,
помещаемых назад в стек.

Для примера попробуем извлечь у парсера хотя бы одно целое число:

\begin{verbatim}
def UnsignedInteger: Rule1[Int] = rule {
  capture(Digit.+) ~> (numStr => numStr.toInt)
}
\end{verbatim}

В этой ситуации поощряется использование фирменного скаловского
плейсходера:

\begin{verbatim}
def UnsignedInteger: Rule1[Int] = rule {
  capture(Digit.+) ~> (_.toInt)
}
\end{verbatim}

Здесь наша лямбда имеет тип \texttt{(String\ =\textgreater{}\ Int)}, что
обуславливает тип нашего правила - \texttt{Rule1{[}Int{]}}. Позволяется
применять оператор \texttt{\textasciitilde{}\textgreater{}} и к
типизированному правилу, например, следующее правило сопоставляет целое
число, но поместит в стек не его, а его удвоенное значение:

\begin{verbatim}
def TwoTimesLarger = rule { UnsignedInteger ~> (i => i * 2) }
\end{verbatim}

Тип правила \texttt{TwoTimesLarger} так и останется
\texttt{Rule1{[}Int{]}}, только на стеке будет лежать другое значение.

\begin{quote}
Явное указание типа аргументов лямбда-функции не самая лучшая идея (по
крайней мере, на момент написания статьи). В компиляторе Scala
существует весьма неприятный баг, который не даст вашему коду нормально
скомпилироваться.
\end{quote}

С одним аргументом мы разобрались, но что делать, если их несколько? Как
поведет себя лямбда? Просто и предсказуемо: первый параметр
соответствует самому верхнему значению на стеке, второй параметр ---
второму сверху, и так далее. Так как процедура захвата подвыражений
выполняется \emph{справа налево}, то порядок аргументов лямбда-функции
соответствует порядку записи операций захвата:

\begin{verbatim}
def UserWithLambda: Rule2[String, String] = rule {
  capture(FirstName) ~ Separator ~ capture(LastName) ~> ((firstName, lastName) => ...)
}
\end{verbatim}

Благодаря оператору действия мы можем уменьшать количество значений на
стеке:

\begin{verbatim}
def UserName = User ~> ((firstName, lastName) => s"$firstName $lastName")
\end{verbatim}

В приведенном примере исходный тип правила \texttt{User} был
\texttt{Rule2{[}String,\ String{]}}, применив к нему лямбда-функцию мы
создали новое правило \texttt{UserFirstName} с типом
\texttt{Rule1{[}String{]}}.

Лямбда не обязана принимать \emph{все} параметры со стека, можно
ограничиться последними N значениями (помним, что лямбда забирает
аргументы с конца стека):

\begin{verbatim}
(foo: Rule2[Int, String]) ~> (_.toDouble)
// bar: Rule2[Int, Double].
\end{verbatim}

Ничего не мешает нам попробовать скормить правилу лямбда-функцию, не
имеющую аргументов, с предсказуемым результатом:

\begin{verbatim}
(foo: Rule0) ~> (() => 42)
// bar: Rule1[Int].
\end{verbatim}

У Parboiled2 есть более мощные инструменты, например, возможность
вернуть из лямбды на стек сразу группу значений:

\begin{verbatim}
(foo: Rule1[Event]) ~> (e => e::DateTime.now()::"localhost"::HNil)
// bar: RuleN[Event::DateTime::String::HNil]
\end{verbatim}

Фактически мы конструируем фирменный шейплессовский \texttt{HList}. Тип
результирующего правила будет
\texttt{RuleN{[}Event::DateTime::String::HNil{]}}.

Аналогично можно забирать значения со стека значений, ничего не отдавая
взамен: для этого лямбда всего-навсего должна «возвращать» тип
\texttt{Unit}. Типом получившегося правила, как вы наверное догадались,
будет \texttt{Rule0}:

\begin{verbatim}
(foo: rule1[String]) ~> (println(_))
// bar: Rule0
\end{verbatim}

Кроме того, оператор действия предлагает особо сладкий сахар для
case-классов:

\begin{verbatim}
case class Person(name: String, age: Int)

(foo: Rule2[String, Int]) ~> Person
// bar: Rule1[Person]
\end{verbatim}

Правда нужно отметить, что компилятор может и не переварить этот сахар,
если для case-класса определен companion object. Тогда придется добавить
лямбду, немного подчеркиваний и записать:
\texttt{\textasciitilde{}\textgreater{}\ (Person(\_,\ \_))}.

Сахар для case-классов идеально подходит для построения AST, опытные
пользователи могут даже заметить, что в этом случае он работает
совершенно аналогично оператору
\texttt{\textasciitilde{}\textasciitilde{}\textgreater{}} из Parboiled1.
Существуют и другие способы применения
\texttt{\textasciitilde{}\textgreater{}} , но о них вы узнаете не от
меня, а из документации. Отмечу только, что оператор
\texttt{\textasciitilde{}\textgreater{}} реализуется в коде Parboiled2
весьма нетривиальным образом, но как бы сложно не выглядело его
определение, пользоваться им одно удовольствие. Пожалуй, самое лучшее
техническое решение, принятое на этапе создания DSL.

\subsection{run}\label{run}

Особая версия оператора действия для любителей острых ощущений. Для
программиста во многих отношениях \texttt{run} ведет себя точно так же,
как и \texttt{\textasciitilde{}\textgreater{}}, кроме того маленького
неудобства, когда в случае с \texttt{run} компилятор не выводит типы
автоматически и их приходится обозначать явно. Оператор является очень
удобным средством для создания непроверяемых сайд-эффектов, например как
здесь:

\begin{verbatim}
def RuleWithSideEffect = rule {
  capture(EmailAddress) ~ run { address: String => send(address, subj, message) } ~ EOI
}
\end{verbatim}

Типом результирующего правила будет \texttt{Rule0}, а сопоставленная
строка оказывается никому не нужна и ни в какой стек значений не
попадет, что иногда бывает необходимо. Пользователи Parboiled1 наверное
заметили, что в описанном выше контексте, \texttt{run} ведет себя так
же, как оператор \texttt{\textasciitilde{}\%}.

\begin{quote}
\textbf{Предупреждение:} При использовании сайд-эффектов, не стоит
заигрывать со стеком значений. Да, к нему можно получить прямой доступ,
но по ряду причин этого лучше не делать.
\end{quote}

\subsection{push}\label{push}

Функция \texttt{push} помещает данные на стек значений в случае, если
соответствующее ему правило сопоставилось. На практике мне не
приходилось пользоваться им часто, так как большую часть работы может
выполнить оператор \texttt{\textasciitilde{}\textgreater{}}, но
существует пример, в котором \texttt{push} просто блистает:

\begin{verbatim}
sealed trait Bool
case object True extends Bool
case object False extends Bool

def BoolMatch = rule { "true" ~ push(True) | "false" ~ push(False) }
\end{verbatim}

\begin{quote}
Хоть это нигде и не отмечено, данное правило следует семантике
call-by-name и вычисляется каждый раз, а значит и его аргумент
вычисляется каждый раз. Обычно это пагубно сказывается на
производительности, поэтому \texttt{push} лучше использовать с
константами и только c константами.
\end{quote}

Так же как в случае с \texttt{run} и
\texttt{\textasciitilde{}\textgreater{}}, тип значения, переданного в
\texttt{push}, определяет содержимое стека и тип создаваемого правила.

\subsection{Вложенные
парсеры}\label{ux432ux43bux43eux436ux435ux43dux43dux44bux435-ux43fux430ux440ux441ux435ux440ux44b}

В Parboiled2 существует поддежрка вложенных парсеров: захватывая текст и
скармливая его оператору \texttt{\textasciitilde{}\textgreater{}} мы
получаем переменную строкового типа в качестве параметра лямбда функции.
Проведя некоторые операции со сторокой мы можем скормить ее
какому-нибудь подпарсеру и так далее. На практике применять не
приходилось, но следует знать, что такая возможность есть.

\section{Генерация
AST}\label{ux433ux435ux43dux435ux440ux430ux446ux438ux44f-ast}

У нас есть все необходимые знания, чтобы написать свой парсер,
генерирующий синтактическое дерево. Синтаксические деревья строятся из
нод. Поэтому начнем с них, вернее с их описания:

\begin{verbatim}
sealed trait AstNode
case class KeyValueNode(key: String, value: String) extends AstNode
case class BlockNode(name: String, nodes: Seq[AstNode]) extends AstNode
\end{verbatim}

Каждый из кейс классов соответствует определенному типу ноды, вроде бы
все ясно и понятно. Тем не менее, давайте постараемся найти что-то общее
среди приведенных выше узлов. У каждого есть имя, просто в случае с
парой ключ-значение это ключ. Узлы между собой различать тоже как-то
нужно.

\begin{verbatim}
sealed trait AstNode {
  def name: String
}

case class KeyValueNode
(override val name: String, value: String) extends AstNode

case class BlockNode
(override val name: String, nodes: Seq[AstNode]) extends AstNode
\end{verbatim}

Начнем с узла для пар ключ-значение. Нам нужно захватить ключ, захватить
значение и собрать это все в case class посредством оператора
\texttt{\textasciitilde{}\textgreater{}}. Захват мы будем делать «на
месте» (в правилах для ключа и значения). И начнем мы с ключа:

\begin{verbatim}
// Можно довериться выводу типов и не указывать тип явно
def Key: Rule1[String] = rule { capture(oneOrMore(KeySymbol)) }
\end{verbatim}

Просто добавляем \texttt{capture} и все --- Parboiled думает о нас.
Строка будет отправлена на стек. А вот с захватом значения ситуация
сложнее. Если мы провернем операцию, аналогичную для ключа, нам придет
строка с кавычками. Они нам нужны? Поэтому захват будем делать на
территории строки:

\begin{verbatim}
def QuotedString: Rule1[String] = rule {
  '"' ~ capture(QuotedStringContent)  ~ '"'
}
\end{verbatim}

Для правила Value ничего делать не нужно, оно автоматически будет иметь
тип Rule1 (так как тело строки было захвачено ранее, со стека оно никуда
не ушло).

\begin{quote}
Захват \texttt{capture} нужно делать один раз. И желательно, в том
правиле, где он должен был произойти
\end{quote}

Теперь соберем case class:

\begin{verbatim}
def KeyValuePair: Rule1[AstNode] = rule {
  Key ~ MayBeWS ~ "=" ~ MayBeWS ~ Value ~> KeyValueNode
}
\end{verbatim}

Используем синтаксический сахар и элегантно упаковываем полученные ключ
и значение в подходящую ноду. Конечно мы можем использовать расширенный
лямбда-синтаксис и выполнить какие-либо преобразования. Но нам они не
нужны. Теперь разберемся со списком нод:

\begin{verbatim}
// тип должен быть объявлен явно, даже если вы полагаетесь на компилятор
def Node: Rule1[AstNode] = rule { KeyValuePair | Block }
\end{verbatim}

Так как каждая из нод захвачена, правило \texttt{Nodes} изменений не
требует, разве что стоит указать тип значения, помещаемого на стек:

\begin{verbatim}
def Nodes: Rule1[Seq[AstNode]] = rule {
  MayBeWS ~ zeroOrMore(Node).separatedBy(NewLine ~ MayBeWS) ~ MayBeWS
}
\end{verbatim}

У нас есть все для описания блочной ноды. Имя захватим на месте,
аналогично правилу для ключа:

\begin{verbatim}
def BlockName: Rule1[String] = rule { capture(oneOrMore(BlockNameSymbol.+)) }
\end{verbatim}

Ноды уже были захвачены, поэтому просто соберем данные в case class:

\begin{verbatim}
def Block: Rule1[AstNode] = rule {
  BlockName ~ MayBeWS ~ BlockBeginning ~ Nodes ~ BlockEnding ~> BlockNode
}
\end{verbatim}

Правило, которое описывает корень дерева, так же состоит из нод, поэтому
можно ничего больше и не делать. И вроде бы все работает хорошо и ничего
менять не хочется, однако результат выглядит не очень красиво: у нас
есть два типа нод, и корень который представляет список нод. И третий
явно лишний. Мы можем представить корень в качестве блока, с особым
именем.

\begin{verbatim}
def Root: Rule1[AstNode] = rule {
  Nodes ~ EOI ~> {nodes: Seq[AstNode] => BlockNode(RootNodeName, nodes)}
}
\end{verbatim}

Какое имя выбрать? Мы можем дать блоку вполне осознанное имя, например
root, но тогда нас могут ждать непредвиденные сюрпризы, если кто-то
захочет выбрать имя root. Зная что BlockName является идентификатором,
который не допускает ряд символов, можно попробовать имена вроде
\texttt{"\$root"}, \texttt{"!root!"} или \texttt{"\%root\%"}. Работать
будет. Я предпочту пустую строку:

\begin{verbatim}
val RootNodeName = ""
\end{verbatim}

Пустая строка:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Удовлетворяет главному требованию --- не является валидным именем
  блока или ключа;
\item
  Отлично подойдет если мы захотим расширить грамматику. Как бы мы не
  мучили парсер, уж что-что, а пустую строку пользователь точно не
  создаст.
\end{itemize}

Теперь у нас есть захваченные данные. Остается только выполнить прогон
из корня для подходящего текста.

\section{DSL для работы с
узлами}\label{dsl-ux434ux43bux44f-ux440ux430ux431ux43eux442ux44b-ux441-ux443ux437ux43bux430ux43cux438}

Получив на руки рабочий парсер, способный отдавать синтаксическое
дерево, мы должны с этим деревом как-то работать. Создание небольшого
DSL значительно упрощает эту задачу. Например, нам нужно перейти к
следующей ноде по имени. Можно каждый раз писать один и тот же код, а
можно сделать небольшой метод (продублированный перегруженным
оператором), способный возвращать следующую ноду. Ниже приведены
основные методы необходимые для работы с AstNode. На базе которых можно
сделать много других (наиболее подходящих под ваши нужды). Если
захотите, можно дать им символьные имена и любоваться красотой
полученного DSL.

\begin{verbatim}
/**
 * Код имеющий крайне опосредованное отношение к parboiled
 */
trait NodeAccessDsl { this: AstNode =>

  def isRoot = this.name == BkvParser.RootNodeName

  lazy val isBlockNode = this match {
    case _: KeyValueNode => false
    case _ => true
  }

  /**
   * В случае блокового узла возвращает список вложенных пар
   * ключ-значение
   */
  def pairs: Seq[KeyValueNode] = this match {
    case BlockNode(_, nodes) =>
      nodes collect { case node: KeyValueNode => node }
    case _ => Seq.empty
  }

  /**
   * В случае блокового узла возвращает спосок вложенных
   * блоков
   */
  def blocks: Seq[BlockNode] = this match {
    case BlockNode(_, nodes) =>
      nodes collect { case node: BlockNode => node }
    case _ => Seq.empty
  }

  /**
   * Значение в случае пары "ключ-значение"
   */
  def getValue: Option[String] = this match {
    case KeyValueNode(_, value) => Some(value)
    case _ => None
  }
}
\end{verbatim}

Хочу отметить, что лишних методов не бывает, и практически каждый раз
требуются: рекурсивный поиск, возможность изменять значения в нодах
(изменяя состояние, либо используя
\href{http://stackoverflow.com/questions/8307370/functional-lenses}{линзы}).
Наличие разнообразных вспомогательных методов, работающих с деревом,
очень сильно упрощает жизнь.

В итоге мы написали функциональный парсер, используя Parboiled2, и
сделали работу с получаемым синтаксическим деревом относительно
комфортной. В следующей статье я расскажу о дополнительных возможностях
библиотеки и о процессе оптимизации производительности. Также будет
рассмотрен процесс миграции с предыдущей версии. Расскажу о недостатках,
и о том как с этими недостатками жить.

С кодом парсера вы можете ознакомиться
\href{https://github.com/ppopoff/bkv-parser}{здесь}.

\section{Производительность}\label{ux43fux440ux43eux438ux437ux432ux43eux434ux438ux442ux435ux43bux44cux43dux43eux441ux442ux44c}

Parboiled2 работает быстро, но иногда он может работать еще быстрее. В
этом разделе мы поговорим о доступных микрооптимизациях. Главное при
выполнении оптимизаций --- своевременность. Но если есть возможность
сразу написать чуть более оптимальный код, не потеряв при этом в
выразительности --- этой возможностью обязательно следует
воспользоваться.

\subsection{\texorpdfstring{Разворачивайте \texttt{n.times} для малых n
\textless{}=
4}{Разворачивайте n.times для малых n \textless{}= 4}}\label{ux440ux430ux437ux432ux43eux440ux430ux447ux438ux432ux430ux439ux442ux435-n.times-ux434ux43bux44f-ux43cux430ux43bux44bux445-n-4}

Вы можете выиграть в производительности, если для малых \emph{n} вместо
оператора повторения \texttt{n.times} просто соедините несколько
повторяющихся правил в цепочку. Сколько повторений имеет смысл
разворачивать --- зависит от обстоятельств, но едва ли это число больше
четырех.

\begin{verbatim}
// Медленно
rule { 4 times Digit }

// Быстро
rule { Digit ~ Digit ~ Digit ~ Digit }
\end{verbatim}

Актуальность этой оптимизации
\href{https://github.com/sirthias/parboiled2/issues/101}{объявлена}
самим Матиасом, хотя, гипотетически, оператор \texttt{n.times} мог бы и
сам ее выполнять.

\subsection{\texorpdfstring{Ускорение операций со стеком для
\texttt{n.times}}{Ускорение операций со стеком для n.times}}\label{ux443ux441ux43aux43eux440ux435ux43dux438ux435-ux43eux43fux435ux440ux430ux446ux438ux439-ux441ux43e-ux441ux442ux435ux43aux43eux43c-ux434ux43bux44f-n.times}

Использование подобной техники позволит вам выжать немножко
производительности и при извлечении данных со стека значений. Например,
так ее можно применить к предыдущему правилу:

\begin{verbatim}
def Digit4 = rule {
  Digit ~ Digit ~ Digit ~ Digit ~
    push(
      #(charAt(-4))*1000 +
      #(charAt(-3))*100 +
      #(charAt(-2))*10 +
      #(lastChar)
    )
}
\end{verbatim}

\subsection{\texorpdfstring{Не пересоздавайте
\texttt{CharPredicate}}{Не пересоздавайте CharPredicate}}\label{ux43dux435-ux43fux435ux440ux435ux441ux43eux437ux434ux430ux432ux430ux439ux442ux435-charpredicate}

Совершенно нормально радоваться новым возможностям класса
\texttt{CharPredicate}, но создавать свои экземпляры типа
\texttt{CharPredicate} внутри блока \texttt{rule} совершенно не стоит:
ваш предикат будет пересоздаваться каждый раз, когда выполняется
правило, что драматически испортит производительность вашего парсера.
Поэтому, вместо того чтобы создавать символьные предикаты каждый раз,
определите их внутри вашего парсера как константу:

\begin{verbatim}
class MyParser(val input: ParserInput) extends Parser {
  val Uppercase = CharPredicate.from(_.isUpper)
  ...
}
\end{verbatim}

или, что еще лучше, отправьте это объявление в объект-компаньон вашего
парсера:

\begin{verbatim}
class MyParser(val input: ParserInput) extends Parser {
  ...
}

object MyParser {
  val Uppercase = CharPredicate.from(_.isUpper)
}
\end{verbatim}

\subsection{Используйте семантические
предикаты}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-ux441ux435ux43cux430ux43dux442ux438ux447ux435ux441ux43aux438ux435-ux43fux440ux435ux434ux438ux43aux430ux442ux44b}

Особенность данных правил состоит в том, что они не взаимодействуют со
стеком значений. Подробно, они описаны в документации, но вот самое
главное, что вы должны о них знать:

\begin{quote}
При использовании семантических предикатов парсер не совершает
прогресса, то есть не перемещает свой курсор на следующий символ.
Поэтому при их бездумном использовании парсер может зациклиться.
\end{quote}

Помните пример с объявлением символьного предиката для символов верхнего
регистра? Вы можете сделать тоже самое, используя семантический предикат
\texttt{test}:

\begin{verbatim}
def JavaUpperCase = rule { oneOrMore(test(currentChar.isUpper) ~ ANY) }
\end{verbatim}

\subsection{\texorpdfstring{Используйте \texttt{ANY} там, где хотели бы
видеть
\texttt{CharPredicate.All}}{Используйте ANY там, где хотели бы видеть CharPredicate.All}}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-any-ux442ux430ux43c-ux433ux434ux435-ux445ux43eux442ux435ux43bux438-ux431ux44b-ux432ux438ux434ux435ux442ux44c-charpredicate.all}

Увы, \texttt{CharPredicate.All} работает медленно для больших диапазонов
символов, \texttt{ANY} работает быстрее. Воспользуйтесь этим знанием.

\subsection{Используйте инвертирующий
предикат}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-ux438ux43dux432ux435ux440ux442ux438ux440ux443ux44eux449ux438ux439-ux43fux440ux435ux434ux438ux43aux430ux442}

Представьте, что ваш парсер должен захватывать все символы до перевода
строки (для определенности, в стиле Unix). Конечно, это можно сделать
при помощи \texttt{noneOf}, но инвертирующий предикат будет быстрее:

\begin{verbatim}
def foo = rule { capture(zeroOrMore(noneOf("\n"))) }

// Быстрее?
def foo = rule { capture(zeroOrMore(!'\n')) }
\end{verbatim}

К сожалению, этот замечательно выглядящий пример зациклит, потому что
парсер не будет совершать прогресса. Чтобы это исправить, необходимо
правило, передвигающее курсор парсера, но при этом не изменяющее стек.
Например, вот такое:

\begin{verbatim}
def foo = rule { capture(zeroOrMore( !'\n' ~ ANY )) }
\end{verbatim}

Теперь правило \texttt{foo} поглотит абсолютно все, кроме \texttt{EOI} и
перевода строки.

\section{Отчеты об
ошибках}\label{ux43eux442ux447ux435ux442ux44b-ux43eux431-ux43eux448ux438ux431ux43aux430ux445}

Не думаю, что вам захочется работать с парсером, выдающим бессмысленные
сообщения при любых некорректных входных данных. Parboiled2 способен
вполне внятно рассказывать об ошибках, если вы ему в этом поможете.

\subsection{Форматирование}\label{ux444ux43eux440ux43cux430ux442ux438ux440ux43eux432ux430ux43dux438ux435}

Итак, если что-то навернулось, парсер передаст в ваше распоряжение
объект типа \texttt{ParseError}, который можно привести в читаемый вид
посредством метода \texttt{formatError}:

\begin{verbatim}
val errorMessage = parser formatError error
\end{verbatim}

Если форматирование по умолчанию вас по каким-то причинам не устраивает,
свои пожелания следует передать парсеру явным образом:

\begin{verbatim}
val errorMessage parser.formatError(error, new ErrorFormatter(showTraces = true))
\end{verbatim}

Если вы захотите написать свой \texttt{ErrorFormatter}, вам придется
самостоятельно разобраться со структурой класса \texttt{ParseError},
который объявлен в глубине Parboiled таким образом:

\begin{verbatim}
case class ParseError(position: Position, charCount: Int, traces: Seq[RuleTrace]) extends RuntimeException
\end{verbatim}

Также стоит отметить наличие нескольких схем доставки сообщений об
ошибке до пользователя: по вашему желанию \texttt{ParseError} может быть
представлен не только в виде объекта \texttt{Try}, а, например, в виде
полиморфного типа или \texttt{Either}. Подробнее можно ознакомиться
\href{https://github.com/sirthias/parboiled2/blob/master/README.rst\#alternative-deliveryschemes}{здесь}.

\begin{verbatim}
def Foo = rule { "foo" | fail("Я упаль!") }
\end{verbatim}

\subsection{Тонкая
настройка}\label{ux442ux43eux43dux43aux430ux44f-ux43dux430ux441ux442ux440ux43eux439ux43aux430}

Существует опция, позволяющая обойти встроенный механизм формирования
сообщений об ошибках. Для этого нужно использовать правило \texttt{fail}
с сообщением, которое вы хотите увидеть в случае ошибки:

\begin{verbatim}
def Goldfinger = rule { "talk" | fail("to die") }
\end{verbatim}

Тогда при удобном случае вы получите назад свое сообщение об ошибке
примерно в такой форме:

\begin{verbatim}
Invalid input 'Bond', expected to die. (line 1, column 1):
\end{verbatim}

\subsection{Именованные
правила}\label{ux438ux43cux435ux43dux43eux432ux430ux43dux43dux44bux435-ux43fux440ux430ux432ux438ux43bux430}

Использование подобного типа правил бывает весьма полезным не только в
целях отлова ошибок. Данный механизм подробно описан в разделе «Best
Practices».

\subsection{atomic}\label{atomic}

Parboiled2 генерирует парсеры, основанные на PEG. Это означает, что
парсеры оперируют символами, а не строками (как многие могли подумать),
поэтому и ошибки вам будут показываться на символьном уровне.
Согласитесь --- сообщение вида «У вас тут X, мы ожидали Y или Z»
потребует больше мысленных усилий, чем «У вас тут XX, а мы ожидали
увидеть XY или XZ». Для того, чтобы видеть строки в отчетах об ошибках
целиком, существует маркер \texttt{atomiс}, всего-то и нужно обернуть в
него правило:

\begin{verbatim}
def AtomicRuleTest = rule { atomic("foo") | atomic("fob") | atomic("bar") }
\end{verbatim}

Чтобы при лисичках (\texttt{foxes}) на входе получить

\begin{verbatim}
Invalid input "fox", expected "foo", "fob" or "bar" (line 1, column 1):
foxes
^
\end{verbatim}

\subsection{quiet}\label{quiet}

Когда вариантов для выбора слишком много, не всегда хочется уведомлять
пользователя о всех возможных альтернативах. Например, в определенном
месте ваш парсер ожидает множество пробельных символов в совокупности с
неким правилом. Для устранения избыточности в отчете, вы, возможно,
захотите умолчать о пробелах. С использованием маркера \texttt{quiet}
это очень просто:

\begin{verbatim}
def OptionalWhitespaces = rule { quiet(zeroOrMore(anyOf(" \t\n"))) }
\end{verbatim}

Честно признаюсь --- ситуаций, поощряющих использования этого правила, я
не встречал. Так же, как и \texttt{atomic}, оно подробно
\href{https://github.com/sirthias/parboiled2/blob/master/README.rst\#the-quiet-marker}{описано
в документации}.

\subsection{Восстановление после
ошибок}\label{ux432ux43eux441ux441ux442ux430ux43dux43eux432ux43bux435ux43dux438ux435-ux43fux43eux441ux43bux435-ux43eux448ux438ux431ux43eux43a}

Практически единственный эпизод, где Parboiled1 выигрывает, а у
Parboiled2 дела обстоят не очень хорошо: парсер падает уже только от
вида первой же встреченной им ошибки. Для большинства сценариев это
отлично подходит: это, например, не мешает парсить логи, текстовые
протоколы, конфигурационные файлы (для ряда случаев), однако
разработчикам DSL или IDE-подобных инструментов такое положение дел
будет не по душе.
\href{https://github.com/sirthias/parboiled2/issues/42}{Матиас обещает
это исправить}, поэтому если вам эта функциональность очень сильно нужна
уже сегодня --- напишите на баг-трекер, возможно это ускорит процесс
разработки.

В Parboiled1 имеется
\href{https://github.com/sirthias/parboiled/wiki/Parse-Error-Handling}{огромное
число ParserRunnerов} на все случаи жизни. Посмотрите в сторону
\texttt{RecoveringParserRunner}, если вам нужно продолжать парсинг в
случае ошибок.

\subsection{Тестирование}\label{ux442ux435ux441ux442ux438ux440ux43eux432ux430ux43dux438ux435}

Разработчики Parboiled используют для тестирования фреймворк
\href{https://etorreborre.github.io/specs2/}{specs2}, который они
дополнили своим вспомогательным классом
\href{http://bit.ly/1Y5iZ9t}{TestParserSpec}. Он покажется неудобным
тем, кто использует scalatest, но основную его идею можно и перенять. По
секрету от Матиаса, его решение не отличается особенной аккуратностью,
так как полагается на изменяемое состояние. Возможно, в будущем нас
будет ждать что-то похожее на полноценный каркас для тестирования.

Правила можно тестировать как по отдельности, так и вместе. Лично я
предпочитаю писать тесты не на каждое правило, а проверять только
главное правило в «особых» случаях:

\begin{quote}
Во многих форматах, даже стандартизованных, могут встречаться весьма
интересные моменты. Например, в BSD-подобном формате сообщений
\href{https://www.ietf.org/rfc/rfc3164.txt}{RFC 3164} под число месяца
\emph{всегда} отводится две позиции, даже если само число имеет один
разряд. Вот пример из самого RFC:

\begin{quote}
If the day of the month is less than 10, then it MUST be represented as
a space and then the number. For example, the 7th day of August would be
represented as \texttt{"Aug\ \ 7"}, with two spaces between the
\texttt{"g"} and the \texttt{"7"}.
\end{quote}
\end{quote}

Помимо подобного рода «интересных моментов» можно скармливать правилу
строки с незакрытыми скобками, недопустимыми символами, проверять
порядок операций со стеком значений.

В тестировании есть еще одна тонкость, с которой вы сразу же
столкнетесь. Предположим, вы хотите оттестировать следующее правило:

\begin{verbatim}
def Decimal: Rule0 = rule {
  ("+" | "-").? ~ Digit.+ ~ "." ~ Digit.+
}
\end{verbatim}

Для этого отправим парсеру заведомо некорректный ввод и будем ждать на
выходе ошибку:

\begin{verbatim}
// Я еще не видел десятичных дробей с двумя разделителями.
val p = new MyParser("12.3.456").Decimal.run()  // Success(())
p.isFailure shouldBe true  // тест упадет
\end{verbatim}

Но при прогоне теста окажется, что парсер вернул удачный результат.
Почему так? В нашем правиле нет \texttt{EOI}, но если если мы добавим в
него \texttt{EOI}, то испортим все правила, которые используют
\texttt{Decimal}. Поэтому придется создать специальное тестирующее
правило, например, при помощи хитрого механизма
\href{https://github.com/sirthias/parboiled2/blob/master/README.rst\#advanced-techniques}{мета-правил}.
Давайте добавим EOI в конце нашего предыдущего примера, и убедимся в
том, что парсер упал с ошибкой:

\begin{verbatim}
Failure(ParseError(Position(5,1,6), Position(5,1,6), <2 traces>))
\end{verbatim}

\section{Недостатки
Parboiled}\label{ux43dux435ux434ux43eux441ux442ux430ux442ux43aux438-parboiled}

\subsection{Parboiled2}\label{parboiled2}

Если недостатки есть у людей, почему бы их не иметь библиотекам? Здесь
Parboiled2 не является исключением.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Длинные, слишком общие и совершенно непонятные сообщения компилятора
  об ошибках, в лучших традициях C++. Наглядный пример приведен на
  рисунке ниже (в правиле нечаянно пропущен оператор
  \texttt{\textasciitilde{}}). Причина связана с выполнением продвинутых
  проверок на типах, которые
  \href{https://github.com/sirthias/parboiled2/issues/106}{обещают
  убрать} в будущих версиях.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics{https://hsto.org/getpro/habr/post_images/ca6/fe6/0a4/ca6fe60a4692d96f4d7e2034bc4eaa0c.png}
\caption{Компилятор грязно ругается}
\end{figure}

\begin{itemize}
\item
  Эта проблема относится больше не к Parboiled2, а к scalac. Компилятору
  может снести крышу, если у лямбды, захватывающей значения со стека,
  явно (не)определены типы аргументов:

\begin{verbatim}
// Может не сработать
def MyRule = rule { oneOrMore(Visible) ~> {s => "[" + s + "]"} }

// Скорее всего сработает
def MyRule = rule { oneOrMore(Visible) ~> {s: String => "[" + s + "]"} }
\end{verbatim}

  Что сработает, а что нет --- зависит от версии вашего компилятора.
\item
  Многие IDE еще не научились поддерживать макровыражения, а Parboiled2
  был построен не без их помощи. Поэтому не стоит верить подчеркиваниям
  вашей среды разработки. Однажды я, забыв об этом, потратил целый день
  на поиск несуществующей ошибки буквально на ровном месте.
\item
  Отсутствие механизма восстановления при неудачном разборе.
  Проектирующих предметно-ориентированные языки, или же тех, кто хочет
  использовать Parboiled2 в качестве фронтэнда к своему компилятору, это
  сильно разочарует. Но над этим
  \href{https://github.com/sirthias/parboiled2/issues/42}{работают}.
  Если вы хотите видеть эту возможность --- пишите, это ускорит
  разработку.
\item
  Я думаю, что многим разработчикам своих небольших IDE и текстовых
  редакторов хотелось бы видеть более гибкие сообщения об ошибках, чем
  те, что предоставляются сейчас. На данный
  \href{https://github.com/sirthias/parboiled2/issues/96}{момент}
  существует всего два способа повлиять на них:

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    именованные правила,
  \item
    именованные вложенные правила.
  \end{itemize}
\end{itemize}

\subsection{Parboiled1}\label{parboiled1}

Большинство проектов все еще написаны на Parboiled1, и вряд-ли что-то
изменится резко и кардинально (в энтерпрайзе), поэтому может быть
полезным знать, как научиться мириться с его недостатками, коих у
Parboiled1 немало. Помимо весьма ограниченного DSL, у Parboiled
существует проблема «Rule8», которая усложняет написание парсера для
логов. Parboiled1 построен так, что на каждое правило с N элементами
имеется по классу, по аналогии со скаловскими кортежами (tuples): есть
\texttt{Rule0}, \texttt{Rule1}, вплоть до \texttt{Rule7}. Этого вполне
достаточно, чтобы распарсить сложные языки программирования, такие как
Java, да и вообще не вызывает существенных проблем при разборе
древовидных структур. А вот если нужно извлечь данные из линейной
структуры, например, сообщения лога-файла, то в это ограничение очень
несложно упереться. Решается это использованием кортежа вместо одного
результирующего правила. Вот пример:

\begin{verbatim}
def Event: Rule1[LogEvent] = rule {
  Header ~ " " ~ UserData ~ " " ~ Message ~~> {
    (header, data, message) => SyslogEvent (
      header._1, header._2, header._3, header._4, header._5, data._1, data._2, message
    )
  }
}
\end{verbatim}

Пусть выглядит убого, зато проблема решена.

\section{Best practices}\label{best-practices}

В этом разделе я расскажу о прописных истинах, работающих для любого
комбинатора парсеров, а так же о нюансах, специфичных для Parboiled2.

\subsection{CharUtils}\label{charutils}

Есть один полезный объект, не затронутый в документации:
\href{http://bit.ly/1NJJ2kd}{CharUtils}. Он содержит ряд статических
методов, способных облегчить вашу жизнь, например: изменение регистра
символов, экранирование, преобразование целочисленных значений в
соответствующие им символы (строки). и др. Его использование, возможно,
сэкономит ваше время.

\subsection{Пишите модульные
тесты}\label{ux43fux438ux448ux438ux442ux435-ux43cux43eux434ux443ux43bux44cux43dux44bux435-ux442ux435ux441ux442ux44b}

Одно небольшое неудачное изменение может сломать вам грамматику и
обеспечить острую ректальную боль. Это банальный совет, которым многие
пренебрегают. Парсер не так сложно протестировать, как, скажем IO: вам
не нужны Mock-объекты и другие ухищрения для этой рутинной, но очень
ценной работы. У нас была целая инфраструктура парсеров. И поверьте,
первое, что я делал при поиске ошибок --- садился и писал тесты, в
случае их отсутствия.

\subsection{Делайте парсеры и правила
маленькими}\label{ux434ux435ux43bux430ux439ux442ux435-ux43fux430ux440ux441ux435ux440ux44b-ux438-ux43fux440ux430ux432ux438ux43bux430-ux43cux430ux43bux435ux43dux44cux43aux438ux43cux438}

Разделяйте ваши парсеры на подпарсеры. Каждый компонент должен делать
что-то вполне определенное. Например если вы парсите LogEvent, у
которого определено поле Timestamp (особенно если этот Timestamp
соответствует какому-нибудь Rfc),то не поленитесь и вынесите его
отдельно.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Во-первых, это уменьшит код вашего основного прасера, и сделает его
  нагляднее.
\item
  Во-вторых, это заметно облегчит тестирование. Вы покроете модульными
  тестами ваш подпарсер. А после этого приступите к разработке главного
  парсера
\end{itemize}

Существуют разные подходы:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Разбивать парсер на трейты и использовать self-typed reference
  (предпочитаю этот способ).
\item
  Объявлять парсеры как самостоятельные сущности и использовать
  композицию.
\item
  Использовать встроенный механизм для создания subParsers.
\end{itemize}

Правила должны быть максимально компактными, но не компактней. Чем
меньше ваши правила, тем легче найти ошибку в грамматике. Очень сложно
понять логику разработчика, если он делает правила длинными, и при этом
многократно использует \texttt{capture}. Усугублять ситуацию может
неявный захват. Указание типа правила также помогает при поддержке.

\subsection{Отправляйте case objects вместо строк в Value
stack}\label{ux43eux442ux43fux440ux430ux432ux43bux44fux439ux442ux435-case-objects-ux432ux43cux435ux441ux442ux43e-ux441ux442ux440ux43eux43a-ux432-value-stack}

Данный совет можно отнести и к оптимизациям, так как это заставит парсер
работать быстрее. Отправляйте в Value stack значимые объекты, а не
строки. Это сделает ваш парсер быстрее, а код нагляднее.

Плохо:

\begin{verbatim}
def logLevel = rule {
  capture("info" | "warning" | "error") ~ ':’
}
\end{verbatim}

Хорошо:

\begin{verbatim}
def logLevel = rule {
    “info:”   ~ push(LogLevel.Info)
  | “warning" ~ push(LogLevel.Warning)
  | “error"   ~ push(LogLevel.Error)
}
\end{verbatim}

\subsection{Используйте упрощенный синтаксис для сборки
объекта}\label{ux438ux441ux43fux43eux43bux44cux437ux443ux439ux442ux435-ux443ux43fux440ux43eux449ux435ux43dux43dux44bux439-ux441ux438ux43dux442ux430ux43aux441ux438ux441-ux434ux43bux44f-ux441ux431ux43eux440ux43aux438-ux43eux431ux44aux435ux43aux442ux430}

Этот красивый способ появился еще в Parboiled1. Никакой магии, просто
конструктор case classа вызывается неявно. Главное, чтобы количество и
тип аргументов, помещаемых на Value Stack, совпадали с сигнатурой
конструктора case classа.

Плохо:

\begin{verbatim}
def charsAST: Rule1[AST] = rule { capture(Characters) ~> ((s: String) => AText(s)) }
\end{verbatim}

Хорошо:

\begin{verbatim}
def charsAST = rule { capture(Characters) ~> AText }
\end{verbatim}

\subsection{Именованные правила (named
rules)}\label{ux438ux43cux435ux43dux43eux432ux430ux43dux43dux44bux435-ux43fux440ux430ux432ux438ux43bux430-named-rules}

Именованные правила заметно упрощают жизнь при получении отчетов об
ошибках, так как дают возможность вместо невнятного имени правила
использовать псевдоним. Или же помечать правила определенным тегом ---
«Это выражение» или «Модифицирует стек». В любом случае знать о данной
функции будет полезно.

Многие пользователи Parboiled1 уже полюбили эту возможность. Например
разработчики Neo4J, использующие Parboiled для разбора языка
\href{http://neo4j.com/docs/2.2.3/cypher-introduction.html}{Cypher}.

Как это выглядит в Parboiled1:

\begin{verbatim}
def Header: Rule1[Header] = rule("I am header") { ... }
\end{verbatim}

В Parboiled2:

\begin{verbatim}
def Header: Rule1[Header] = namedRule("header is here") { ... }
\end{verbatim}

Так же есть возможность давать имена вложенным правилам:

\begin{verbatim}
def UserName = rule { Prefix ~ oneOrMore(NameChar).named("username") ~ PostFix }
\end{verbatim}

\section{Миграция}\label{ux43cux438ux433ux440ux430ux446ux438ux44f}

Миграция --- процесс, чаще всего, несложный, но времени отнимает немало.
Поэтому я постараюсь хотя бы немного сэкономить драгоценные часы вашей
жизни и описать основные подводные камни.

\subsection{Classpath}\label{classpath}

Для того, чтобы избежать конфликтов с первой версией, Parboiled2
использует classpath \texttt{org.parboiled2} (тогда как classpath для
первой версии \texttt{org.parboiled}). Мавеновский \texttt{groupId},
однако, остался старым: \texttt{org.parboiled}. Благодаря этому, можно
иметь обе зависимости в одном проекте и осуществлять постепенный переход
на новую версию. Что, кстати, работает весьма неплохо при наличии
нескольких автономных парсеров. Если же ваши парсеры состоят из
множества модулей, переиспользуемых в разных местах (как это было в моем
случае) --- вам придется делать миграцию сразу и для всех модулей.

\subsection{Проверка
тестов}\label{ux43fux440ux43eux432ux435ux440ux43aux430-ux442ux435ux441ux442ux43eux432}

Убедитесь в наличии и работоспособности модульных тестов. Они же у вас
есть? Нет? Напишите их. В процессе миграции мне приходилось уточнять
некоторые грамматики из-за того, что новый DSL стал мощнее, и нечаянные
изменения ломали грамматики. Падающие тесты экономили много времени. С
серьезными проблемами, вроде поломки всей грамматики целиком, при
миграции я не сталкивался. Может быть кто-то поделится опытом, если с
ним это произошло.

\subsection{Код вокруг
парсера}\label{ux43aux43eux434-ux432ux43eux43aux440ux443ux433-ux43fux430ux440ux441ux435ux440ux430}

Теперь парсер будет пересоздаваться каждый раз, что не всегда удобно. С
PB1 я очень любил создавать парсер единожды, а потом многократно его
использовать. Теперь этот номер не пройдет. Поэтому вам придется
изменить конструктор парсера и немного переписать использующий его код,
и не бойтесь, что это ухудшит производительность.

\begin{quote}
\textbf{Предупреждение} Parboiled1 позволяет генерировать правила во
время выполнения. Поэтому если у вас имеется подобный персер, то вам,
скорее всего, придется его переписать: Parboiled2 использует
макровыражения которые делают динамику весьма затруднительной, взамен
давая лучшую производительность.
\end{quote}

\subsection{Композиция}\label{ux43aux43eux43cux43fux43eux437ux438ux446ux438ux44f}

Подход к композиции элементов парсера не изменился, это хорошая новость
для мигрирующих. Однако \texttt{Parser} теперь не трейт, а абстрактный
класс. Трейты (traits) --- удобнейшее средство композиции програмных
компонентов, в PB1 это позволяло подмешивать \texttt{Parser} в любые
модули, смешивая модули между собой. Изменение в пользу абстрактного
класса на эту возможность никак не повлияло, но теперь для этого нужно
использовать
\href{http://docs.scala-lang.org/tutorials/tour/explicitly-typed-self-references.html}{self-typed
reference}:

\begin{verbatim}
trait Numbers { this: Parser =>
  // Ваш код
}
\end{verbatim}

Тем, кто подобную возможность языка не использовал и каждый раз
подмешивал трейт \texttt{Parser}, придется изменить свои вкусовые
предпочтения.

В качестве альтернативного способа, вы можете сделать из ваших трейтов
полноправные парсеры и импортировать из них нужные правила (как методы)
в ваш основной парсер. Я, правда, все равно предпочитаю использовать
композиции трейтов, потому как нахожу их более наглядными: мне понятней
видеть парсер собранный из кусков, вместо множественных импортов.

\subsection{Избавляемся от
примитивов}\label{ux438ux437ux431ux430ux432ux43bux44fux435ux43cux441ux44f-ux43eux442-ux43fux440ux438ux43cux438ux442ux438ux432ux43eux432}

В процессе миграции обязательно устройте ревизию своей личной
библиотечки примитивных правил: удалите все что имеется в
\texttt{CharPredicate}. Ваша библиотечка похудеет, однако не исчезнет
совсем. Многие хотели бы добавить в parboiled поддержку различных
форматов дат, грамматику описывающую электронную почту, заголовки HTTP.
Parboiled просто комбинатор парсеров: он таковым был, таким и останется.
Однако согласитесь, что выбрасывать старый код очень приятно.

\section{Заключение}\label{ux437ux430ux43aux43bux44eux447ux435ux43dux438ux435}

В этой серии статей я попытался рассказать вам про самый прогрессивный и
перспективный инструмент парсинга, существующий для языка scala. Сделал
небольшой туториал и рассказал о проблемах, с которыми мне пришлось
столкнуться на практике. Надеюсь, что эта статья в худшем случае
окажется для вас полезной, а в лучшем --- станет руководством к
действию.

\section{Использованные
источники}\label{ux438ux441ux43fux43eux43bux44cux437ux43eux432ux430ux43dux43dux44bux435-ux438ux441ux442ux43eux447ux43dux438ux43aux438}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \href{https://groups.google.com/forum/\#!topic/parboiled-user/Ygb_M6XU5P8}{Список
  рассылки проекта Parboiled}
\item
  \href{http://www.youtube.com/watch?v=qZg4D62K4aQ}{Презентация
  Александра Мыльцева} и
  \href{http://myltsev.name/ScalaDays2014/\#/}{слайды к ней}
\item
  \href{http://bit.ly/1H2ZQ3A}{Примеры кода из репозитория Parboiled}
\item
  \href{https://github.com/sirthias/parboiled2/tree/master/scalaParser/src}{Парсер
  языка scala, написаный при помощи Parboiled2}
\end{itemize}

\end(document)
